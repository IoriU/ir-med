{"cells":[{"cell_type":"markdown","source":["Link drive untuk keseluruhan program dan weight dari model\n","https://drive.google.com/drive/folders/1n7aADZefyso8p4TqZvdtimTNwBFPkFNc?usp=sharing"],"metadata":{"id":"Mr9Tp6nV7kB8"}},{"cell_type":"markdown","metadata":{"id":"thTCPhss2E7D"},"source":["# Util"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GWaIzJ6w2G-0"},"outputs":[],"source":["class IdMap:\n","    \"\"\"\n","    Ingat kembali di kuliah, bahwa secara praktis, sebuah dokumen dan\n","    sebuah term akan direpresentasikan sebagai sebuah integer. Oleh\n","    karena itu, kita perlu maintain mapping antara string term (atau\n","    dokumen) ke integer yang bersesuaian, dan sebaliknya. Kelas IdMap ini\n","    akan melakukan hal tersebut.\n","    \"\"\"\n","\n","    def __init__(self):\n","        \"\"\"\n","        Mapping dari string (term atau nama dokumen) ke id disimpan dalam\n","        python's dictionary; cukup efisien. Mapping sebaliknya disimpan dalam\n","        python's list.\n","\n","        contoh:\n","            str_to_id[\"halo\"] ---> 8\n","            str_to_id[\"/collection/dir0/gamma.txt\"] ---> 54\n","\n","            id_to_str[8] ---> \"halo\"\n","            id_to_str[54] ---> \"/collection/dir0/gamma.txt\"\n","        \"\"\"\n","        self.str_to_id = {}\n","        self.id_to_str = []\n","\n","    def __len__(self):\n","        \"\"\"Mengembalikan banyaknya term (atau dokumen) yang disimpan di IdMap.\"\"\"\n","        return len(self.id_to_str)\n","\n","    def __get_str(self, i):\n","        \"\"\"Mengembalikan string yang terasosiasi dengan index i.\"\"\"\n","        # TODO\n","        return self.id_to_str[i]\n","\n","    def __get_id(self, s):\n","        \"\"\"\n","        Mengembalikan integer id i yang berkorespondensi dengan sebuah string s.\n","        Jika s tidak ada pada IdMap, lalu assign sebuah integer id baru dan kembalikan\n","        integer id baru tersebut.\n","        \"\"\"\n","        # TODO\n","        if (s not in self.id_to_str):\n","            self.id_to_str.append(s)\n","            self.str_to_id[s] = len(self.id_to_str) - 1\n","        return self.str_to_id[s]\n","\n","    def __getitem__(self, key):\n","        \"\"\"\n","        __getitem__(...) adalah special method di Python, yang mengizinkan sebuah\n","        collection class (seperti IdMap ini) mempunyai mekanisme akses atau\n","        modifikasi elemen dengan syntax [..] seperti pada list dan dictionary di Python.\n","\n","        Silakan search informasi ini di Web search engine favorit Anda. Saya mendapatkan\n","        link berikut:\n","\n","        https://stackoverflow.com/questions/43627405/understanding-getitem-method\n","\n","        Jika key adalah integer, gunakan __get_str;\n","        jika key adalah string, gunakan __get_id\n","        \"\"\"\n","        if type(key) is int:\n","            return self.__get_str(key)\n","        elif type(key) is str:\n","            return self.__get_id(key)\n","        else:\n","            raise TypeError\n","\n","def sorted_merge_posts_and_tfs(posts_tfs1, posts_tfs2):\n","    \"\"\"\n","    Menggabung (merge) dua lists of tuples (doc id, tf) dan mengembalikan\n","    hasil penggabungan keduanya (TF perlu diakumulasikan untuk semua tuple\n","    dengn doc id yang sama), dengan aturan berikut:\n","\n","    contoh: posts_tfs1 = [(1, 34), (3, 2), (4, 23)]\n","            posts_tfs2 = [(1, 11), (2, 4), (4, 3 ), (6, 13)]\n","\n","            return   [(1, 34+11), (2, 4), (3, 2), (4, 23+3), (6, 13)]\n","                   = [(1, 45), (2, 4), (3, 2), (4, 26), (6, 13)]\n","\n","    Parameters\n","    ----------\n","    list1: List[(Comparable, int)]\n","    list2: List[(Comparable, int]\n","        Dua buah sorted list of tuples yang akan di-merge.\n","\n","    Returns\n","    -------\n","    List[(Comparablem, int)]\n","        Penggabungan yang sudah terurut\n","    \"\"\"\n","    result = []\n","    i = j = 0\n","    while i < len(posts_tfs1) and j < len(posts_tfs2):\n","        if (posts_tfs1[i][0] == posts_tfs2[j][0]):\n","            result.append((posts_tfs1[i][0], posts_tfs1[i][1] + posts_tfs2[j][1]))\n","            i += 1; j+= 1\n","        elif (posts_tfs1[i][0] < posts_tfs2[j][0]):\n","            result.append(posts_tfs1[i])\n","            i += 1\n","        elif (posts_tfs1[i][0] > posts_tfs2[j][0]):\n","            result.append(posts_tfs2[j])\n","            j += 1\n","    while (i < len(posts_tfs1)):\n","        result.append(posts_tfs1[i])\n","        i += 1\n","    while (j < len(posts_tfs2)):\n","        result.append(posts_tfs2[j])\n","        j += 1\n","    return result"]},{"cell_type":"markdown","metadata":{"id":"qaPW6yJ31-UG"},"source":["# Compression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dzcuMNxB19hz"},"outputs":[],"source":["import array\n","class StandardPostings:\n","    \"\"\" \n","    Class dengan static methods, untuk mengubah representasi postings list\n","    yang awalnya adalah List of integer, berubah menjadi sequence of bytes.\n","    Kita menggunakan Library array di Python.\n","\n","    ASUMSI: postings_list untuk sebuah term MUAT di memori!\n","\n","    Silakan pelajari:\n","        https://docs.python.org/3/library/array.html\n","    \"\"\"\n","\n","    @staticmethod\n","    def encode(postings_list):\n","        \"\"\"\n","        Encode postings_list menjadi stream of bytes\n","\n","        Parameters\n","        ----------\n","        postings_list: List[int]\n","            List of docIDs (postings)\n","\n","        Returns\n","        -------\n","        bytes\n","            bytearray yang merepresentasikan urutan integer di postings_list\n","        \"\"\"\n","        # Untuk yang standard, gunakan L untuk unsigned long, karena docID\n","        # tidak akan negatif. Dan kita asumsikan docID yang paling besar\n","        # cukup ditampung di representasi 4 byte unsigned.\n","        return array.array('L', postings_list).tobytes()\n","\n","    @staticmethod\n","    def decode(encoded_postings_list):\n","        \"\"\"\n","        Decodes postings_list dari sebuah stream of bytes\n","\n","        Parameters\n","        ----------\n","        encoded_postings_list: bytes\n","            bytearray merepresentasikan encoded postings list sebagai keluaran\n","            dari static method encode di atas.\n","\n","        Returns\n","        -------\n","        List[int]\n","            list of docIDs yang merupakan hasil decoding dari encoded_postings_list\n","        \"\"\"\n","        decoded_postings_list = array.array('L')\n","        decoded_postings_list.frombytes(encoded_postings_list)\n","        return decoded_postings_list.tolist()\n","\n","    @staticmethod\n","    def encode_tf(tf_list):\n","        \"\"\"\n","        Encode list of term frequencies menjadi stream of bytes\n","\n","        Parameters\n","        ----------\n","        tf_list: List[int]\n","            List of term frequencies\n","\n","        Returns\n","        -------\n","        bytes\n","            bytearray yang merepresentasikan nilai raw TF kemunculan term di setiap\n","            dokumen pada list of postings\n","        \"\"\"\n","        return StandardPostings.encode(tf_list)\n","\n","    @staticmethod\n","    def decode_tf(encoded_tf_list):\n","        \"\"\"\n","        Decodes list of term frequencies dari sebuah stream of bytes\n","\n","        Parameters\n","        ----------\n","        encoded_tf_list: bytes\n","            bytearray merepresentasikan encoded term frequencies list sebagai keluaran\n","            dari static method encode_tf di atas.\n","\n","        Returns\n","        -------\n","        List[int]\n","            List of term frequencies yang merupakan hasil decoding dari encoded_tf_list\n","        \"\"\"\n","        return StandardPostings.decode(encoded_tf_list)\n","\n","class VBEPostings:\n","    \"\"\" \n","    Berbeda dengan StandardPostings, dimana untuk suatu postings list,\n","    yang disimpan di disk adalah sequence of integers asli dari postings\n","    list tersebut apa adanya.\n","\n","    Pada VBEPostings, kali ini, yang disimpan adalah gap-nya, kecuali\n","    posting yang pertama. Barulah setelah itu di-encode dengan Variable-Byte\n","    Enconding algorithm ke bytestream.\n","\n","    Contoh:\n","    postings list [34, 67, 89, 454] akan diubah dulu menjadi gap-based,\n","    yaitu [34, 33, 22, 365]. Barulah setelah itu di-encode dengan algoritma\n","    compression Variable-Byte Encoding, dan kemudian diubah ke bytesream.\n","\n","    ASUMSI: postings_list untuk sebuah term MUAT di memori!\n","\n","    \"\"\"\n","\n","    @staticmethod\n","    def vb_encode_number(number):\n","        \"\"\"\n","        Encodes a number using Variable-Byte Encoding\n","        Lihat buku teks kita!\n","        \"\"\"\n","        bytes = []\n","        while True:\n","            bytes.insert(0, number % 128) # prepend ke depan\n","            if number < 128:\n","                break\n","            number = number // 128\n","        bytes[-1] += 128 # bit awal pada byte terakhir diganti 1\n","        return array.array('B', bytes).tobytes()\n","\n","    @staticmethod\n","    def vb_encode(list_of_numbers):\n","        \"\"\" \n","        Melakukan encoding (tentunya dengan compression) terhadap\n","        list of numbers, dengan Variable-Byte Encoding\n","        \"\"\"\n","        bytes = []\n","        for number in list_of_numbers:\n","            bytes.append(VBEPostings.vb_encode_number(number))\n","        return b\"\".join(bytes)\n","\n","    @staticmethod\n","    def encode(postings_list):\n","        \"\"\"\n","        Encode postings_list menjadi stream of bytes (dengan Variable-Byte\n","        Encoding). JANGAN LUPA diubah dulu ke gap-based list, sebelum\n","        di-encode dan diubah ke bytearray.\n","\n","        Parameters\n","        ----------\n","        postings_list: List[int]\n","            List of docIDs (postings)\n","\n","        Returns\n","        -------\n","        bytes\n","            bytearray yang merepresentasikan urutan integer di postings_list\n","        \"\"\"\n","        diff = [postings_list[0] if postings_list != [] else None]\n","        for i in range(1, len(postings_list)):\n","            diff.append(postings_list[i] - postings_list[i-1])\n","        return VBEPostings.vb_encode(diff)\n","\n","    @staticmethod\n","    def encode_tf(tf_list):\n","        \"\"\"\n","        Encode list of term frequencies menjadi stream of bytes\n","\n","        Parameters\n","        ----------\n","        tf_list: List[int]\n","            List of term frequencies\n","\n","        Returns\n","        -------\n","        bytes\n","            bytearray yang merepresentasikan nilai raw TF kemunculan term di setiap\n","            dokumen pada list of postings\n","        \"\"\"\n","        return VBEPostings.vb_encode(tf_list)\n","\n","    @staticmethod\n","    def vb_decode(encoded_bytestream):\n","        \"\"\"\n","        Decoding sebuah bytestream yang sebelumnya di-encode dengan\n","        variable-byte encoding.\n","        \"\"\"\n","        # TODO\n","        return None\n","\n","    @staticmethod\n","    def vb_decode(encoded_bytestream):\n","        \"\"\"\n","        Decoding sebuah bytestream yang sebelumnya di-encode dengan\n","        variable-byte encoding.\n","        \"\"\"\n","        numbers = []\n","        n = 0\n","        for byte in encoded_bytestream:\n","            if (byte < 128):\n","                n = 128 * n + byte\n","            else:\n","                n = 128 * n + byte - 128\n","                numbers.append(n)\n","                n = 0\n","        return numbers\n","\n","    @staticmethod\n","    def decode(encoded_postings_list):\n","        \"\"\"\n","        Decodes postings_list dari sebuah stream of bytes. JANGAN LUPA\n","        bytestream yang di-decode dari encoded_postings_list masih berupa\n","        gap-based list.\n","\n","        Parameters\n","        ----------\n","        encoded_postings_list: bytes\n","            bytearray merepresentasikan encoded postings list sebagai keluaran\n","            dari static method encode di atas.\n","\n","        Returns\n","        -------\n","        List[int]\n","            list of docIDs yang merupakan hasil decoding dari encoded_postings_list\n","        \"\"\"\n","        diff = VBEPostings.vb_decode(encoded_postings_list)\n","        decoded = [diff[0] if diff != [] else None]\n","        for i in range(1, len(diff)):\n","            decoded.append(diff[i] + decoded[i-1])\n","        return decoded\n","\n","    @staticmethod\n","    def decode_tf(encoded_tf_list):\n","        \"\"\"\n","        Decodes list of term frequencies dari sebuah stream of bytes\n","\n","        Parameters\n","        ----------\n","        encoded_tf_list: bytes\n","            bytearray merepresentasikan encoded term frequencies list sebagai keluaran\n","            dari static method encode_tf di atas.\n","\n","        Returns\n","        -------\n","        List[int]\n","            List of term frequencies yang merupakan hasil decoding dari encoded_tf_list\n","        \"\"\"\n","        return VBEPostings.vb_decode(encoded_tf_list)"]},{"cell_type":"markdown","metadata":{"id":"exsyofeY2Pzv"},"source":["# Index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FGz5sJmW2Q94"},"outputs":[],"source":["import pickle\n","import os\n","class InvertedIndex:\n","    \"\"\"\n","    Class yang mengimplementasikan bagaimana caranya scan atau membaca secara\n","    efisien Inverted Index yang disimpan di sebuah file; dan juga menyediakan\n","    mekanisme untuk menulis Inverted Index ke file (storage) saat melakukan indexing.\n","\n","    Attributes\n","    ----------\n","    postings_dict: Dictionary mapping:\n","\n","            termID -> (start_position_in_index_file,\n","                       number_of_postings_in_list,\n","                       length_in_bytes_of_postings_list,\n","                       length_in_bytes_of_tf_list)\n","\n","        postings_dict adalah konsep \"Dictionary\" yang merupakan bagian dari\n","        Inverted Index. postings_dict ini diasumsikan dapat dimuat semuanya\n","        di memori.\n","\n","        Seperti namanya, \"Dictionary\" diimplementasikan sebagai python's Dictionary\n","        yang memetakan term ID (integer) ke 4-tuple:\n","           1. start_position_in_index_file : (dalam satuan bytes) posisi dimana\n","              postings yang bersesuaian berada di file (storage). Kita bisa\n","              menggunakan operasi \"seek\" untuk mencapainya.\n","           2. number_of_postings_in_list : berapa banyak docID yang ada pada\n","              postings (Document Frequency)\n","           3. length_in_bytes_of_postings_list : panjang postings list dalam\n","              satuan byte.\n","           4. length_in_bytes_of_tf_list : panjang list of term frequencies dari\n","              postings list terkait dalam satuan byte\n","\n","    terms: List[int]\n","        List of terms IDs, untuk mengingat urutan terms yang dimasukan ke\n","        dalam Inverted Index.\n","\n","    \"\"\"\n","    def __init__(self, index_name, postings_encoding, directory=''):\n","        \"\"\"\n","        Parameters\n","        ----------\n","        index_name (str): Nama yang digunakan untuk menyimpan files yang berisi index\n","        postings_encoding : Lihat di compression.py, kandidatnya adalah StandardPostings,\n","                        GapBasedPostings, dsb.\n","        directory (str): directory dimana file index berada\n","        \"\"\"\n","\n","        self.index_file_path = os.path.join(directory, index_name+'.index')\n","        self.metadata_file_path = os.path.join(directory, index_name+'.dict')\n","\n","        self.postings_encoding = postings_encoding\n","        self.directory = directory\n","\n","        self.postings_dict = {}\n","        self.terms = []         # Untuk keep track urutan term yang dimasukkan ke index\n","        self.doc_length = {}    # key: doc ID (int), value: document length (number of tokens)\n","                                # Ini nantinya akan berguna untuk normalisasi Score terhadap panjang\n","                                # dokumen saat menghitung score dengan TF-IDF atau BM25\n","        self.doc_length_average = 0\n","\n","    def __enter__(self):\n","        \"\"\"\n","        Memuat semua metadata ketika memasuki context.\n","        Metadata:\n","            1. Dictionary ---> postings_dict\n","            2. iterator untuk List yang berisi urutan term yang masuk ke\n","                index saat konstruksi. ---> term_iter\n","            3. doc_length, sebuah python's dictionary yang berisi key = doc id, dan\n","                value berupa banyaknya token dalam dokumen tersebut (panjang dokumen).\n","                Berguna untuk normalisasi panjang saat menggunakan TF-IDF atau BM25\n","                scoring regime; berguna untuk untuk mengetahui nilai N saat hitung IDF,\n","                dimana N adalah banyaknya dokumen di koleksi\n","\n","        Metadata disimpan ke file dengan bantuan library \"pickle\"\n","\n","        Perlu memahani juga special method __enter__(..) pada Python dan juga\n","        konsep Context Manager di Python. Silakan pelajari link berikut:\n","\n","        https://docs.python.org/3/reference/datamodel.html#object.__enter__\n","        \"\"\"\n","        # Membuka index file\n","        if (not os.path.isfile(self.index_file_path)):\n","          open(self.index_file_path, 'w+')\n","        self.index_file = open(self.index_file_path, 'rb+')\n","\n","        # Kita muat postings dict dan terms iterator dari file metadata\n","        if (not os.path.isfile(self.metadata_file_path)):\n","          open(self.metadata_file_path, 'w+')\n","        with open(self.metadata_file_path, 'rb') as f:\n","            self.postings_dict, self.terms, self.doc_length, self.doc_length_average = pickle.load(f)\n","            self.term_iter = self.terms.__iter__()\n","\n","        return self\n","\n","    def __exit__(self, exception_type, exception_value, traceback):\n","        \"\"\"Menutup index_file dan menyimpan postings_dict dan terms ketika keluar context\"\"\"\n","        # Menutup index file\n","        self.index_file.close()\n","        self.doc_length_average = sum(self.doc_length.values())/len(self.doc_length.values())\n","        # Menyimpan metadata (postings dict dan terms) ke file metadata dengan bantuan pickle\n","        with open(self.metadata_file_path, 'wb') as f:\n","            pickle.dump([self.postings_dict, self.terms, self.doc_length, self.doc_length_average], f)\n","\n","\n","class InvertedIndexReader(InvertedIndex):\n","    \"\"\"\n","    Class yang mengimplementasikan bagaimana caranya scan atau membaca secara\n","    efisien Inverted Index yang disimpan di sebuah file.\n","    \"\"\"\n","    def __iter__(self):\n","        return self\n","\n","    def reset(self):\n","        \"\"\"\n","        Kembalikan file pointer ke awal, dan kembalikan pointer iterator\n","        term ke awal\n","        \"\"\"\n","        self.index_file.seek(0)\n","        self.term_iter = self.terms.__iter__() # reset term iterator\n","\n","    def __next__(self): \n","        \"\"\"\n","        Class InvertedIndexReader juga bersifat iterable (mempunyai iterator).\n","        Silakan pelajari:\n","        https://stackoverflow.com/questions/19151/how-to-build-a-basic-iterator\n","\n","        Ketika instance dari kelas InvertedIndexReader ini digunakan\n","        sebagai iterator pada sebuah loop scheme, special method __next__(...)\n","        bertugas untuk mengembalikan pasangan (term, postings_list, tf_list) berikutnya\n","        pada inverted index.\n","\n","        PERHATIAN! method ini harus mengembalikan sebagian kecil data dari\n","        file index yang besar. Mengapa hanya sebagian kecil? karena agar muat\n","        diproses di memori. JANGAN MEMUAT SEMUA INDEX DI MEMORI!\n","        \"\"\"\n","        curr_term = next(self.term_iter)\n","        pos, number_of_postings, len_in_bytes_of_postings, len_in_bytes_of_tf = self.postings_dict[curr_term]\n","        postings_list = self.postings_encoding.decode(self.index_file.read(len_in_bytes_of_postings))\n","        tf_list = self.postings_encoding.decode_tf(self.index_file.read(len_in_bytes_of_tf))\n","        return (curr_term, postings_list, tf_list)\n","\n","    def get_postings_list(self, term):\n","        \"\"\"\n","        Kembalikan sebuah postings list (list of docIDs) beserta list\n","        of term frequencies terkait untuk sebuah term (disimpan dalam\n","        bentuk tuple (postings_list, tf_list)).\n","\n","        PERHATIAN! method tidak boleh iterasi di keseluruhan index\n","        dari awal hingga akhir. Method ini harus langsung loncat ke posisi\n","        byte tertentu pada file (index file) dimana postings list (dan juga\n","        list of TF) dari term disimpan.\n","        \"\"\"\n","        # TODO\n","        if term in self.postings_dict:\n","            metadata = self.postings_dict[term]\n","            self.index_file.seek(metadata[0])\n","            posting_byte = self.index_file.read(metadata[2])\n","            tf_byte = self.index_file.read(metadata[3])\n","            decoded_posting = self.postings_encoding.decode(posting_byte)\n","            decoded_tf = self.postings_encoding.decode_tf(tf_byte)\n","            decoded = list(zip(decoded_posting, decoded_tf))\n","        else:\n","            decoded = []\n","        return decoded\n","\n","\n","class InvertedIndexWriter(InvertedIndex):\n","    \"\"\"\n","    Class yang mengimplementasikan bagaimana caranya menulis secara\n","    efisien Inverted Index yang disimpan di sebuah file.\n","    \"\"\"\n","    def __enter__(self):\n","        self.index_file = open(self.index_file_path, 'wb+')\n","        return self\n","\n","    def append(self, term, postings_list, tf_list):\n","        \"\"\"\n","        Menambahkan (append) sebuah term, postings_list, dan juga TF list \n","        yang terasosiasi ke posisi akhir index file.\n","\n","        Method ini melakukan 4 hal:\n","        1. Encode postings_list menggunakan self.postings_encoding (method encode),\n","        2. Encode tf_list menggunakan self.postings_encoding (method encode_tf),\n","        3. Menyimpan metadata dalam bentuk self.terms, self.postings_dict, dan self.doc_length.\n","           Ingat kembali bahwa self.postings_dict memetakan sebuah termID ke\n","           sebuah 4-tuple: - start_position_in_index_file\n","                           - number_of_postings_in_list\n","                           - length_in_bytes_of_postings_list\n","                           - length_in_bytes_of_tf_list\n","        4. Menambahkan (append) bystream dari postings_list yang sudah di-encode dan\n","           tf_list yang sudah di-encode ke posisi akhir index file di harddisk.\n","\n","        Jangan lupa update self.terms dan self.doc_length juga ya!\n","\n","        SEARCH ON YOUR FAVORITE SEARCH ENGINE:\n","        - Anda mungkin mau membaca tentang Python I/O\n","          https://docs.python.org/3/tutorial/inputoutput.html\n","          Di link ini juga bisa kita pelajari bagaimana menambahkan informasi\n","          ke bagian akhir file.\n","        - Beberapa method dari object file yang mungkin berguna seperti seek(...)\n","          dan tell()\n","\n","        Parameters\n","        ----------\n","        term:\n","            term atau termID yang merupakan unique identifier dari sebuah term\n","        postings_list: List[Int]\n","            List of docIDs dimana term muncul\n","        tf_list: List[Int]\n","            List of term frequencies\n","        \"\"\"\n","        # TODO\n","        \n","        encode_posting = self.postings_encoding.encode(postings_list)\n","        encode_tf = self.postings_encoding.encode_tf(tf_list)\n","        self.postings_dict[term] = (self.index_file.tell(), len(postings_list), len(encode_posting), len(encode_tf))\n","        self.index_file.write(encode_posting)\n","        self.index_file.write(encode_tf)\n","        self.terms.append(term)\n","        for i in range(len(postings_list)):\n","            if (postings_list[i] in self.doc_length):\n","                self.doc_length[postings_list[i]] = self.doc_length[postings_list[i]] + tf_list[i]\n","            else:\n","                self.doc_length[postings_list[i]] = tf_list[i]"]},{"cell_type":"markdown","metadata":{"id":"9uC-cQQn154R"},"source":["# BSBI"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZhiGXpYi6tWt"},"outputs":[],"source":["!mkdir index"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1980,"status":"ok","timestamp":1670659633159,"user":{"displayName":"Hendrico Kristiawan","userId":"15526653224856737825"},"user_tz":-420},"id":"JQv9-VFd1rpV","outputId":"c139f601-cd93-409c-8e9b-482d47ffc608"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["import os\n","import pickle\n","import contextlib\n","import heapq\n","import time\n","import math\n","\n","from tqdm import tqdm\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem.snowball import SnowballStemmer\n","import re\n","class BSBIIndex:\n","    \"\"\"\n","    Attributes\n","    ----------\n","    term_id_map(IdMap): Untuk mapping terms ke termIDs\n","    doc_id_map(IdMap): Untuk mapping relative paths dari dokumen (misal,\n","                    /collection/0/gamma.txt) to docIDs\n","    data_dir(str): Path ke data\n","    output_dir(str): Path ke output index files\n","    postings_encoding: Lihat di compression.py, kandidatnya adalah StandardPostings,\n","                    VBEPostings, dsb.\n","    index_name(str): Nama dari file yang berisi inverted index\n","    \"\"\"\n","    def __init__(self, data_dir, output_dir, postings_encoding, index_name = \"main_index\"):\n","        self.term_id_map = IdMap()\n","        self.doc_id_map = IdMap()\n","        self.data_dir = data_dir\n","        self.output_dir = output_dir\n","        self.index_name = index_name\n","        self.postings_encoding = postings_encoding\n","        self.stemmer = SnowballStemmer(language = \"english\")\n","        # Untuk menyimpan nama-nama file dari semua intermediate inverted index\n","        self.intermediate_indices = []\n","        self.load()\n","\n","    def save(self):\n","        \"\"\"Menyimpan doc_id_map and term_id_map ke output directory via pickle\"\"\"\n","        with open(os.path.join(self.output_dir, 'terms.dict'), 'wb') as f:\n","            pickle.dump(self.term_id_map, f)\n","        with open(os.path.join(self.output_dir, 'docs.dict'), 'wb') as f:\n","            pickle.dump(self.doc_id_map, f)\n","\n","    def load(self):\n","        \"\"\"Memuat doc_id_map and term_id_map dari output directory\"\"\"\n","        try:\n","            with open(os.path.join(self.output_dir, 'terms.dict'), 'rb') as f:\n","                self.term_id_map = pickle.load(f)\n","            with open(os.path.join(self.output_dir, 'docs.dict'), 'rb') as f:\n","                self.doc_id_map = pickle.load(f)\n","        except:\n","            print(\"Create File\")\n","\n","    def clean_text(self, text):\n","        text = text.lower()\n","        text = re.sub(\"\\s+\", \" \", text) # Menghilangkan spasi berlebih\n","        text = re.sub(\"[^\\w\\s]\", \" \", text) # Menghilangkan tanda baca'\n","        stop_words = set(stopwords.words('english'))\n","        res = word_tokenize(text)\n","        res = [w for w in res if w not in stop_words]\n","        return [self.stemmer.stem(w) for w in res]\n","\n","    def parse_block(self, block_dir_relative):\n","        \"\"\"\n","        Lakukan parsing terhadap text file sehingga menjadi sequence of\n","        <termID, docID> pairs.\n","\n","        Gunakan tools available untuk Stemming Bahasa Inggris\n","\n","        JANGAN LUPA BUANG STOPWORDS!\n","\n","        Untuk \"sentence segmentation\" dan \"tokenization\", bisa menggunakan\n","        regex atau boleh juga menggunakan tools lain yang berbasis machine\n","        learning.\n","\n","        Parameters\n","        ----------\n","        block_dir_relative : str\n","            Relative Path ke directory yang mengandung text files untuk sebuah block.\n","\n","            CATAT bahwa satu folder di collection dianggap merepresentasikan satu block.\n","            Konsep block di soal tugas ini berbeda dengan konsep block yang terkait\n","            dengan operating systems.\n","\n","        Returns\n","        -------\n","        List[Tuple[Int, Int]]\n","            Returns all the td_pairs extracted from the block\n","            Mengembalikan semua pasangan <termID, docID> dari sebuah block (dalam hal\n","            ini sebuah sub-direktori di dalam folder collection)\n","\n","        Harus menggunakan self.term_id_map dan self.doc_id_map untuk mendapatkan\n","        termIDs dan docIDs. Dua variable ini harus 'persist' untuk semua pemanggilan\n","        parse_block(...).\n","        \"\"\"\n","        # TODO\n","        collection_path = os.path.join(self.data_dir, block_dir_relative)\n","        td_pairs = []\n","        for filename in os.listdir(collection_path):\n","            with open(os.path.join(collection_path, filename), 'r') as f: # open in readonly mode\n","                doc_id = self.doc_id_map[os.path.join(collection_path, filename)]\n","                text = f.read()\n","                tokens = self.clean_text(text)\n","                for token in tokens:\n","                    term_id = self.term_id_map[token]\n","                    td_pairs.append((term_id, doc_id))\n","        return td_pairs\n","    \n","    def invert_write(self, td_pairs, index):\n","        \"\"\"\n","        Melakukan inversion td_pairs (list of <termID, docID> pairs) dan\n","        menyimpan mereka ke index. Disini diterapkan konsep BSBI dimana \n","        hanya di-mantain satu dictionary besar untuk keseluruhan block.\n","        Namun dalam teknik penyimpanannya digunakan srategi dari SPIMI\n","        yaitu penggunaan struktur data hashtable (dalam Python bisa\n","        berupa Dictionary)\n","\n","        ASUMSI: td_pairs CUKUP di memori\n","\n","        Di Tugas Pemrograman 1, kita hanya menambahkan term dan\n","        juga list of sorted Doc IDs. Sekarang di Tugas Pemrograman 2,\n","        kita juga perlu tambahkan list of TF.\n","\n","        Parameters\n","        ----------\n","        td_pairs: List[Tuple[Int, Int]]\n","            List of termID-docID pairs\n","        index: InvertedIndexWriter\n","            Inverted index pada disk (file) yang terkait dengan suatu \"block\"\n","        \"\"\"\n","        term_dict = {}\n","        for term_id, doc_id in td_pairs:\n","            if term_id not in term_dict:\n","                term_dict[term_id] = {}\n","            if (doc_id not in term_dict[term_id].keys()):\n","                term_dict[term_id][doc_id] = 0\n","            term_dict[term_id][doc_id] +=1\n","        for term_id in sorted(term_dict.keys()):\n","            posting_list = sorted(list(term_dict[term_id]))\n","            tf_list = []\n","            for i in posting_list:\n","                tf_list.append(term_dict[term_id][i])\n","            index.append(term_id, posting_list, tf_list)\n","        \n","        \n","\n","    def merge(self, indices, merged_index):\n","        \"\"\"\n","        Lakukan merging ke semua intermediate inverted indices menjadi\n","        sebuah single index.\n","\n","        Ini adalah bagian yang melakukan EXTERNAL MERGE SORT\n","\n","        Gunakan fungsi orted_merge_posts_and_tfs(..) di modul util\n","\n","        Parameters\n","        ----------\n","        indices: List[InvertedIndexReader]\n","            A list of intermediate InvertedIndexReader objects, masing-masing\n","            merepresentasikan sebuah intermediate inveted index yang iterable\n","            di sebuah block.\n","\n","        merged_index: InvertedIndexWriter\n","            Instance InvertedIndexWriter object yang merupakan hasil merging dari\n","            semua intermediate InvertedIndexWriter objects.\n","        \"\"\"\n","        # kode berikut mengasumsikan minimal ada 1 term\n","        merged_iter = heapq.merge(*indices, key = lambda x: x[0])\n","        curr, postings, tf_list = next(merged_iter) # first item\n","        for t, postings_, tf_list_ in merged_iter: # from the second item\n","            if t == curr:\n","                zip_p_tf = sorted_merge_posts_and_tfs(list(zip(postings, tf_list)), \\\n","                                                      list(zip(postings_, tf_list_)))\n","                postings = [doc_id for (doc_id, _) in zip_p_tf]\n","                tf_list = [tf for (_, tf) in zip_p_tf]\n","            else:\n","                merged_index.append(curr, postings, tf_list)\n","                curr, postings, tf_list = t, postings_, tf_list_\n","        merged_index.append(curr, postings, tf_list)\n","\n","    def bm25_okapi(self, tf, df, N, dl, avdl,k1 = 1.2, b=0.75):\n","        \"\"\"\n","        Menghitung score dokumen dengan metode BM25 tanpa normalisasi panjang dokumen.\n","\n","        Parameters\n","        ----------\n","        tf: int\n","            Term frequency \n","        df: int\n","            Document frequency\n","        N:  int\n","            Total document\n","        k1: float\n","            Fine tuning\n","        \"\"\"\n","        return math.log10(N/df) * ((k1+1) * tf)/(k1 * ((1-b) + b * (dl/avdl)) + tf)\n","\n","    def tf_n(self, tf):\n","        return tf\n","    def tf_l(self, tf):\n","        return (1 + math.log10(tf)) if tf > 0 else 0\n","    def tf_b(self, tf):\n","        return 1 if tf > 0 else 0\n","    def df_n(self, df, N):\n","        return 1\n","    def df_t(self, df, N):\n","        return (math.log10(N/df))\n","    def df_p(self, df, N):\n","        return max(0, math.log10((N-df)/df))\n","\n","    def tfidf(self, notation, raw_tf, raw_df, N):\n","        \"\"\"\n","        Menghitung score dokumen dengan metode BM25 tanpa normalisasi panjang dokumen.\n","\n","        Parameters\n","        ----------\n","        notation: string\n","            Smart notation for tf-idf\n","        tf: int\n","            Term frequency \n","        df: int\n","            Document frequency\n","        N:  int\n","            Total document\n","        \"\"\"\n","        tf = 0\n","        df = 0\n","        if (notation[0] == \"n\"):\n","            tf = self.tf_n(raw_tf)\n","        elif (notation[0] == \"l\"):\n","            tf = self.tf_l(raw_tf)\n","        elif (notation[0] == \"b\"):\n","            tf = self.tf_b(raw_tf)\n","        if (notation[1] == \"n\"):\n","            df = self.df_n(raw_df, N)\n","        elif (notation[1] == \"t\"):\n","            df = self.df_t(raw_df, N)\n","        elif (notation[1] == \"p\"):\n","            df = self.df_p(raw_df, N)\n","        return tf * df\n","\n","    def retrieve_tfidf(self, query, k = 10, notation = \"ltn\"):\n","        \"\"\"\n","        Melakukan Ranked Retrieval dengan skema TaaT (Term-at-a-Time).\n","        Method akan mengembalikan top-K retrieval results.\n","\n","        w(t, D) = (1 + log tf(t, D))       jika tf(t, D) > 0\n","                = 0                        jika sebaliknya\n","\n","        w(t, Q) = IDF = log (N / df(t))\n","\n","        Score = untuk setiap term di query, akumulasikan w(t, Q) * w(t, D).\n","                (tidak perlu dinormalisasi dengan panjang dokumen)\n","\n","        catatan: \n","            1. informasi DF(t) ada di dictionary postings_dict pada merged index\n","            2. informasi TF(t, D) ada di tf_li\n","            3. informasi N bisa didapat dari doc_length pada merged index, len(doc_length)\n","\n","        Parameters\n","        ----------\n","        query: str\n","            Query tokens yang dipisahkan oleh spasi\n","\n","            contoh: Query \"universitas indonesia depok\" artinya ada\n","            tiga terms: universitas, indonesia, dan depok\n","\n","        Result\n","        ------\n","        List[(int, str)]\n","            List of tuple: elemen pertama adalah score similarity, dan yang\n","            kedua adalah nama dokumen.\n","            Daftar Top-K dokumen terurut mengecil BERDASARKAN SKOR.\n","\n","        JANGAN LEMPAR ERROR/EXCEPTION untuk terms yang TIDAK ADA di collection.\n","\n","        \"\"\"\n","        # TODO\n","        tokens = self.clean_text(query)\n","        page_dict = {}\n","        result = []\n","        with InvertedIndexReader(self.index_name, self.postings_encoding, directory = self.output_dir) as merged_index:\n","            for token in tokens:\n","                term_id = self.term_id_map[token]\n","                postings = merged_index.get_postings_list(term_id)\n","                for (doc_id, tf) in postings: \n","                    doc_str = self.doc_id_map[doc_id]\n","                    if (doc_str not in page_dict):\n","                        page_dict[doc_str] = 0\n","                    page_dict[doc_str] += self.tfidf(notation, tf, merged_index.postings_dict[doc_id][1], len(self.doc_id_map))\n","            result = list(zip(page_dict.values(), page_dict.keys()))\n","        result = sorted(result, key=lambda x: x[0], reverse=True)\n","        return result[:k]\n","\n","    def retrieve_bm25(self, query, k = 10, k1 = 1.2, b = 0.75):\n","        \"\"\"\n","        Melakukan Ranked Retrieval dengan skema TaaT (Term-at-a-Time).\n","        Method akan mengembalikan top-K retrieval results.\n","\n","        w(t, D) = (1 + log tf(t, D))       jika tf(t, D) > 0\n","                = 0                        jika sebaliknya\n","\n","        w(t, Q) = IDF = log (N / df(t))\n","\n","        Score = untuk setiap term di query, akumulasikan w(t, Q) * w(t, D).\n","                (tidak perlu dinormalisasi dengan panjang dokumen)\n","\n","        catatan: \n","            1. informasi DF(t) ada di dictionary postings_dict pada merged index\n","            2. informasi TF(t, D) ada di tf_li\n","            3. informasi N bisa didapat dari doc_length pada merged index, len(doc_length)\n","\n","        Parameters\n","        ----------\n","        query: str\n","            Query tokens yang dipisahkan oleh spasi\n","\n","            contoh: Query \"universitas indonesia depok\" artinya ada\n","            tiga terms: universitas, indonesia, dan depok\n","\n","        Result\n","        ------\n","        List[(int, str)]\n","            List of tuple: elemen pertama adalah score similarity, dan yang\n","            kedua adalah nama dokumen.\n","            Daftar Top-K dokumen terurut mengecil BERDASARKAN SKOR.\n","\n","        JANGAN LEMPAR ERROR/EXCEPTION untuk terms yang TIDAK ADA di collection.\n","\n","        \"\"\"\n","        # TODO\n","        tokens = self.clean_text(query)\n","        page_dict = {}\n","        result = []\n","        with InvertedIndexReader(self.index_name, self.postings_encoding, directory = self.output_dir) as merged_index:\n","            for token in tokens:\n","                term_id = self.term_id_map[token]\n","                postings = merged_index.get_postings_list(term_id)\n","                for (doc_id, tf) in postings: \n","                    doc_str = self.doc_id_map[doc_id]\n","                    if (doc_str not in page_dict):\n","                        page_dict[doc_str] = 0\n","                    page_dict[doc_str] += self.bm25_okapi(tf, merged_index.postings_dict[doc_id][1], len(self.doc_id_map), \\\n","                        merged_index.doc_length[doc_id], merged_index.doc_length_average, k1, b)\n","            result = list(zip(page_dict.values(), page_dict.keys()))\n","        result = sorted(result, key=lambda x: x[0], reverse=True)\n","        return result[:k]\n","\n","    def index(self):\n","        \"\"\"\n","        Base indexing code\n","        BAGIAN UTAMA untuk melakukan Indexing dengan skema BSBI (blocked-sort\n","        based indexing)\n","\n","        Method ini scan terhadap semua data di collection, memanggil parse_block\n","        untuk parsing dokumen dan memanggil invert_write yang melakukan inversion\n","        di setiap block dan menyimpannya ke index yang baru.\n","        \"\"\"\n","        # loop untuk setiap sub-directory di dalam folder collection (setiap block)\n","        for block_dir_relative in tqdm(sorted(next(os.walk(self.data_dir))[1])):\n","            td_pairs = self.parse_block(block_dir_relative)\n","            index_id = 'intermediate_index_'+block_dir_relative\n","            self.intermediate_indices.append(index_id)\n","            with InvertedIndexWriter(index_id, self.postings_encoding, directory = self.output_dir) as index:\n","                self.invert_write(td_pairs, index)\n","                td_pairs = None\n","        self.save()\n","        with InvertedIndexWriter(self.index_name, self.postings_encoding, directory = self.output_dir) as merged_index:\n","            with contextlib.ExitStack() as stack:\n","                indices = [stack.enter_context(InvertedIndexReader(index_id, self.postings_encoding, directory=self.output_dir))\n","                               for index_id in self.intermediate_indices]\n","                self.merge(indices, merged_index)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":109675,"status":"ok","timestamp":1670659742816,"user":{"displayName":"Hendrico Kristiawan","userId":"15526653224856737825"},"user_tz":-420},"id":"MROtF-z59uF8","outputId":"dfb225df-899f-433e-bee0-3518dbda7480"},"outputs":[{"output_type":"stream","name":"stdout","text":["Create File\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 11/11 [01:48<00:00,  9.89s/it]\n"]}],"source":["BSBI_instance = BSBIIndex(data_dir = '/content/drive/MyDrive/IR/collection', \\\n","                              postings_encoding = VBEPostings, \\\n","                              output_dir = 'index')\n","BSBI_instance.index() # memulai indexing!\n"]},{"cell_type":"markdown","metadata":{"id":"IO1YdL8d3Rs8"},"source":["# Mono Roberta"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XrxXV3bv3b12"},"outputs":[],"source":["from IPython.display import clear_output\n","!pip install transformers\n","clear_output()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AeAnhVvN3T6l"},"outputs":[],"source":["from transformers import TFRobertaModel\n","from keras.layers import Dropout, Dense\n","from keras.optimizers import Adam\n","import tensorflow as tf\n","from keras.losses import SparseCategoricalCrossentropy\n","from keras.metrics import SparseCategoricalAccuracy\n","from transformers import RobertaTokenizer\n","class MonoRoberta(tf.keras.Model):\n","\n","    def __init__(self, model_name, dropout_prob=0.1):\n","        super().__init__(name=\"reranker\")\n","        self.tokenizer = RobertaTokenizer.from_pretrained(model_name)\n","        self.roberta = TFRobertaModel.from_pretrained(model_name, from_pt=True)\n","        self.dropout = Dropout(dropout_prob)\n","        weight_initializer = tf.keras.initializers.GlorotNormal() \n","        self.classifier = Dense(3, name=\"classifier\", \n","                                # activation = 'softmax',\n","                                kernel_initializer = weight_initializer,  \n","                                bias_initializer = 'zeros')\n","\n","    def call(self, inputs, **kwargs):\n","        trained_roberta = self.roberta(inputs, **kwargs)\n","        pooled_output = trained_roberta.pooler_output\n","        pooled_output = self.dropout(pooled_output,\n","                                     training=kwargs.get(\"training\", False))\n","        logits = self.classifier(pooled_output)\n","        return logits\n","    "]},{"cell_type":"markdown","metadata":{"id":"cInAIOHRRISN"},"source":["# DPR Roberta"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jbRYfA08RKSW"},"outputs":[],"source":["from transformers import TFRobertaModel\n","from keras.layers import Dropout, Dense, Dot\n","from keras.optimizers import Adam\n","from keras.losses import SparseCategoricalCrossentropy\n","from keras.metrics import SparseCategoricalAccuracy\n","\n","class DPRRoberta(tf.keras.Model):\n","\n","    def __init__(self, model_name, dropout_prob=0.3):\n","        super().__init__(name=\"reranker\")\n","        self.tokenizer = RobertaTokenizer.from_pretrained(model_name)\n","        self.roberta_query = TFRobertaModel.from_pretrained(model_name, from_pt=True)\n","        self.roberta_doc = TFRobertaModel.from_pretrained(model_name, from_pt=True)\n","        self.dropout = Dropout(dropout_prob)\n","        self.dot = Dot(axes=1)\n","\n","\n","    def call(self, query, doc, **kwargs):\n","        trained_query = self.roberta_query(query, **kwargs)\n","        trained_doc= self.roberta_doc(doc, **kwargs)\n","        pooled_query = trained_query.pooler_output\n","        pooled_doc = trained_doc.pooler_output\n","        return self.dot([pooled_query, pooled_doc])"]},{"cell_type":"markdown","metadata":{"id":"rdQVlIR52a-E"},"source":["# Letor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L3_o0IkykUF2"},"outputs":[],"source":["import transformers\n","transformers.logging.set_verbosity_error()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-CZAGCIc2cq4"},"outputs":[],"source":["class Letor:\n","    def reranking(self, query, docs_path):\n","        docs = []\n","        for doc_path in docs_path:\n","            docs.append((doc_path[1], open(doc_path[1], \"r\").read()))\n","        scores = self.predict(query, docs)\n","        did_scores = [x for x in zip(scores, [did for (did, _) in docs])]\n","        # return did_scores\n","        return sorted(did_scores, key = lambda tup: tup[0], reverse = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YF24iJ1CVOdJ"},"outputs":[],"source":["class LetorMono(Letor):\n","    def __init__(self, model_name):\n","        self.model = MonoRoberta(model_name)\n","    \n","    def prepare_model(self, model_path):\n","        encoded_input = self.model.tokenizer(\"a\", \"b\", padding=True, truncation=True, max_length=256, return_tensors='tf')\n","        self.model(encoded_input)\n","        self.model.load_weights(model_path)\n","\n","    def predict(self, query, docs):\n","          scores = []\n","          for doc in docs:\n","              x = self.model.tokenizer(query, doc[1], padding=\"max_length\", truncation=True, max_length=256, return_tensors='tf')\n","              out = self.model(x).numpy()[0]\n","              scores.append(out[2])\n","          return scores\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ho4LV3iVkYh"},"outputs":[],"source":["class LetorDPR(Letor):\n","    def __init__(self, model_name):\n","        self.model = DPRRoberta(model_name)\n","    \n","    def prepare_model(self, model_path):\n","        x_q = self.model.tokenizer(\"a\", padding=\"max_length\", truncation=True, max_length=50, return_tensors='tf')\n","        x_d = self.model.tokenizer(\"b\", padding=\"max_length\", truncation=True, max_length=206, return_tensors='tf')\n","        self.model(x_q, x_d)\n","        self.model.load_weights(model_path)\n","\n","    def predict(self, query, docs):\n","          scores = []\n","          for doc in docs:\n","              x_q = self.model.tokenizer(query, padding=\"max_length\", truncation=True, max_length=50, return_tensors='tf')\n","              x_d = self.model.tokenizer(doc[1], padding=\"max_length\", truncation=True, max_length=206, return_tensors='tf')\n","              scores.append(self.model(x_q, x_d).numpy()[0][0])\n","          return scores\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":519,"referenced_widgets":["e0ebf753bb3a440880b489dd7c2e2644","e39423d94c694875996c24f4ac485f01","20989918523b4ec8b81e0103d2039011","3e00fdfa4c12432986f815e583cf0c07","ee3de834e8b341a69c3a0595d208782e","282e6f992eda44278fdbbec26982c724","886a6d19748e42cbbf6c067a3ef57749","502bc0e2337d4db5854abbcf59b816e3","8d85f54585244ec58ccdad64729ec49b","3285fc0713254c528fbcc68363d15c18","74ba9596bbbf432fab7fc3e1635a99d1","3014f36332344ff5bb869e7cc74ce37b","201bcfb40cec45fca500dc27efda5d9e","c3a8dd6555fd4554a1847847e2d8f983","fd8b17423af245139d9c6d7dd2b7aa54","356fc7cdce6341688b55f9454909bc10","23b4194295724f5c9633f0e43887be4b","353f1aca1ca147e2a1ebb4fda536135c","9479ab7b73cc488193591493963616cc","abc073a72da3499391cc77482e1981e3","abc4549bb4284bdb93d901980a91962d","b7e32fa2168146be81b9cdc67d9fefc4","1031e6d90ff640099144d31e1ec55969","c1f9608c2313445888b3239788f547ef","d58aa0bdfcf24388b7c384a34e1e938a","4173371099ea4b6db36d71a7d476e10b","9083a86d40cc419aa7ba669cf331daef","faea5e14b35f4e359c617f558b1b7adc","15ffdfa4db2e4217a355c3672c67a273","97c30e467cec4895a52075189df4a70e","2ad004a5a3b04e30bf1dbd31e84d4a19","01314a24a3864a42842f7c7f78966d71","bab646e5400b4769a58db0e089711736","035fc08c3466460884e67bab7f9054b8","4bab9fcd29234053b5026d0bfe667024","5b2822d6c3004255ad30defda0d4bc5b","5cde4d11cb334f75992b7c4765612172","1cc92491c8aa4f6698ba50f6a5963f51","7a5e2826ef804b50891c250c70c39073","f7a374023b664017aca5ab5bcdf57190","02af1c080367484eac6e17242fa54c73","4ae101f4ab7f494fb8ed1c9325663178","900e4c7c93fc462db3884a782bfaa811","0d08b677bd654fad9fcda146dddffb42","b5922ee25e694fcf8d307e31ed35d283","f2d302859e234ed18871e9a6965eab2d","f2c955d03c39417db0dec7319072d87c","21a474385bd14d2cafa9a80c5526c64a","061df2e20e284569b7ac8a38c1f1c227","6c0792bd89454b019656e5bb6cc28711","e3ab9f7ef53d409ea640b1516117fd15","5878106a99ae48189fc4c13c8c814d4a","22f881e0d935478aaf1db3509a9c8729","af99f65edf1648889bc01947ae68632a","4988aaa93fdd409d91adc5f77cc0e1f0","0921b9adbd644a9caefb4d6972275ab5","e798d7e9fbed431e820a4aac62ff3d6b","27d1facf27de4874bccbc134bc8bd2cf","932e67a91bce48a2aaa82c2da182d915","e6308c36df2e40b9b74945b6aa83b26e","7d6445b12c34489b913f39f03c3597b5","5d169d9bf94d493cb993aa8faee13980","29bfbaaa20b14fbea93b3d6c1eb55fda","723d69450b714d5a9184ae44254a8949","a2e75f81fbcd4aa4b35238f6b3e0db69","9cf9ec9f89f24f6387258475c388faf5","398af7a51e5943a1ae4e094d774df571","facf4780e7304086b990a327e578c7d6","59d2ecfbc82f47a89feee46f1acb3ddf","b19194cbead04c81ae9d715468c780c9","31bfe2ed22504e218335a1bd66993b4b","74d0f547bc84443a9308dd402441dd4b","fe56c50899b848c082220c6d443bf2d3","7f6dacee2bff4de4aab4600c76d2c330","9e1f2e0689f04959aab6faba4962d213","ef9ccf227473421f80710037c39ea9fc","464c223a3e0b4f99a4929eca21a94c64"]},"executionInfo":{"elapsed":44854,"status":"ok","timestamp":1670659803180,"user":{"displayName":"Hendrico Kristiawan","userId":"15526653224856737825"},"user_tz":-420},"id":"NXLBBHwH3yWI","outputId":"2adc51e4-36f3-4d18-d05b-fd8293c78c18"},"outputs":[{"output_type":"stream","name":"stdout","text":["Query  :  alkylated\n","Results:\n","/content/drive/MyDrive/IR/collection/10/989.txt 2.549\n","/content/drive/MyDrive/IR/collection/6/547.txt 2.373\n","/content/drive/MyDrive/IR/collection/11/1003.txt 1.921\n","/content/drive/MyDrive/IR/collection/6/507.txt 1.829\n","/content/drive/MyDrive/IR/collection/8/785.txt 1.813\n","/content/drive/MyDrive/IR/collection/5/482.txt 1.727\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0ebf753bb3a440880b489dd7c2e2644"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3014f36332344ff5bb869e7cc74ce37b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1031e6d90ff640099144d31e1ec55969"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"035fc08c3466460884e67bab7f9054b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/185 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5922ee25e694fcf8d307e31ed35d283"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/430 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0921b9adbd644a9caefb4d6972275ab5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/656M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"398af7a51e5943a1ae4e094d774df571"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Results :\n","/content/drive/MyDrive/IR/collection/6/507.txt 1.1304115\n","/content/drive/MyDrive/IR/collection/11/1003.txt 0.70857996\n","/content/drive/MyDrive/IR/collection/6/547.txt 0.6443668\n","/content/drive/MyDrive/IR/collection/8/785.txt 0.48496473\n","/content/drive/MyDrive/IR/collection/5/482.txt 0.4375329\n","/content/drive/MyDrive/IR/collection/10/989.txt 0.24341339\n"]}],"source":["BSBI_instance = BSBIIndex(data_dir = '/content/drive/MyDrive/IR/collection', \\\n","                      postings_encoding = VBEPostings, \\\n","                      output_dir = 'index')\n","query = \"alkylated\"\n","bsbi = BSBI_instance.retrieve_bm25(query, k = 10, k1=1.2, b=0.75)\n","print(\"Query  : \", query)\n","print(\"Results:\")\n","for (score, doc) in bsbi:\n","    print(f\"{doc:30} {score:>.3f}\")\n","print()\n","letor_instance = LetorMono(\"allenai/biomed_roberta_base\")\n","letor_instance.prepare_model(\"/content/drive/MyDrive/IR/mono roberta/checkpoint/20.h5\")\n","letor = letor_instance.reranking(query, bsbi)\n","print(\"Results :\")\n","for (score, did) in letor:\n","    print(did, score)"]},{"cell_type":"markdown","metadata":{"id":"7xiBLZaqAQN2"},"source":["# Eksperimen"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BGs59m0KARqH"},"outputs":[],"source":["import math\n","import re\n","from tqdm import tqdm\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","######## >>>>> 3 IR metrics: RBP p = 0.8, DCG, dan AP\n","qr_count = {'Q1': 37, 'Q2': 16, 'Q3': 22, 'Q4': 23, 'Q5': 26, 'Q6': 13, 'Q7': 15, 'Q8': 11, 'Q9': 28, 'Q10': 24, 'Q11': 18, 'Q12': 9, 'Q13': 21, 'Q14': 16, 'Q15': 29, 'Q16': 13, 'Q17': 21, 'Q18': 15, 'Q19': 27, 'Q20': 39, 'Q21': 27, 'Q22': 25, 'Q23': 39, 'Q24': 22, 'Q25': 24, 'Q26': 28, 'Q27': 18, 'Q28': 39, 'Q29': 37, 'Q30': 14}\n","def rbp(ranking, p = 0.8):\n","  \"\"\" menghitung search effectiveness metric score dengan \n","      Rank Biased Precision (RBP)\n","\n","      Parameters\n","      ----------\n","      ranking: List[int]\n","         vektor biner seperti [1, 0, 1, 1, 1, 0]\n","         gold standard relevansi dari dokumen di rank 1, 2, 3, dst.\n","         Contoh: [1, 0, 1, 1, 1, 0] berarti dokumen di rank-1 relevan,\n","                 di rank-2 tidak relevan, di rank-3,4,5 relevan, dan\n","                 di rank-6 tidak relevan\n","        \n","      Returns\n","      -------\n","      Float\n","        score RBP\n","  \"\"\"\n","  score = 0.\n","  for i in range(1, len(ranking) + 1):\n","    pos = i - 1\n","    score += ranking[pos] * (p ** (i - 1))\n","  return (1 - p) * score\n","\n","def irbp(ranking, key, p = 0.8):\n","  \"\"\" menghitung ideal RBP ketika semua ranking merupakan qrels.\n","\n","      Parameters\n","      ----------\n","      ranking: List[int]\n","         vektor biner seperti [1, 0, 1, 1, 1, 0]\n","         gold standard relevansi dari dokumen di rank 1, 2, 3, dst.\n","         Contoh: [1, 0, 1, 1, 1, 0] berarti dokumen di rank-1 relevan,\n","                 di rank-2 tidak relevan, di rank-3,4,5 relevan, dan\n","                 di rank-6 tidak relevan\n","        \n","      Returns\n","      -------\n","      Float\n","        score RBP\n","  \"\"\"\n","  score = 0.\n","  for i in range(1, len(ranking) + 1):\n","    rank = 1 if i <= qr_count[key] else 0\n","    pos = i - 1\n","    score += rank * (p ** (i - 1))\n","  return (1 - p) * score\n","\n","def dcg(ranking):\n","  \"\"\" menghitung search effectiveness metric score dengan \n","      Discounted Cumulative Gain\n","\n","      Parameters\n","      ----------\n","      ranking: List[int]\n","         vektor biner seperti [1, 0, 1, 1, 1, 0]\n","         gold standard relevansi dari dokumen di rank 1, 2, 3, dst.\n","         Contoh: [1, 0, 1, 1, 1, 0] berarti dokumen di rank-1 relevan,\n","                 di rank-2 tidak relevan, di rank-3,4,5 relevan, dan\n","                 di rank-6 tidak relevan\n","        \n","      Returns\n","      -------\n","      Float\n","        score DCG\n","  \"\"\"\n","  score = 0\n","  for i in range(len(ranking)):\n","    score += (1/math.log2(i+2)) * ranking[i]\n","  return score\n","\n","def idcg(ranking, key):\n","  \"\"\" menghitung ideal DCG ketika semua ranking merupakan qrels.\n","\n","      Parameters\n","      ----------\n","      ranking: List[int]\n","         vektor biner seperti [1, 0, 1, 1, 1, 0]\n","         gold standard relevansi dari dokumen di rank 1, 2, 3, dst.\n","         Contoh: [1, 0, 1, 1, 1, 0] berarti dokumen di rank-1 relevan,\n","                 di rank-2 tidak relevan, di rank-3,4,5 relevan, dan\n","                 di rank-6 tidak relevan\n","        \n","      Returns\n","      -------\n","      Float\n","        score DCG\n","  \"\"\"\n","  score = 0\n","  for i in range(len(ranking)):\n","    rank = 1 if i < qr_count[key] else 0\n","    score += (1/math.log2(i+2)) * rank\n","  return score\n","\n","def prec(ranking, k):\n","  score = 0\n","  for i in range(1, k+1):\n","    score += (1/k) * ranking[i-1] \n","  return score \n","\n","def iprec(ranking, k, key):\n","  score = 0\n","  for i in range(1, k+1):\n","    rank = 1 if i <= qr_count[key] else 0\n","    score += (1/k) * rank\n","  return score \n","\n","def ap(ranking):\n","  \"\"\" menghitung search effectiveness metric score dengan \n","      Average Precision\n","\n","      Parameters\n","      ----------\n","      ranking: List[int]\n","         vektor biner seperti [1, 0, 1, 1, 1, 0]\n","         gold standard relevansi dari dokumen di rank 1, 2, 3, dst.\n","         Contoh: [1, 0, 1, 1, 1, 0] berarti dokumen di rank-1 relevan,\n","                 di rank-2 tidak relevan, di rank-3,4,5 relevan, dan\n","                 di rank-6 tidak relevan\n","        \n","      Returns\n","      -------\n","      Float\n","        score AP\n","  \"\"\"\n","  # TODO\n","  score = 0\n","  R = len(list(filter(lambda x: x == 1, ranking)))\n","  for i in range(len(ranking)):\n","    if (ranking[i]):\n","      score += prec(ranking, i+1)/R\n","  return score\n","\n","def iap(ranking, key):\n","  \"\"\" menghitung ideal AP ketika semua ranking merupakan qrels.\n","\n","      Parameters\n","      ----------\n","      ranking: List[int]\n","         vektor biner seperti [1, 0, 1, 1, 1, 0]\n","         gold standard relevansi dari dokumen di rank 1, 2, 3, dst.\n","         Contoh: [1, 0, 1, 1, 1, 0] berarti dokumen di rank-1 relevan,\n","                 di rank-2 tidak relevan, di rank-3,4,5 relevan, dan\n","                 di rank-6 tidak relevan\n","        \n","      Returns\n","      -------\n","      Float\n","        score AP\n","  \"\"\"\n","  # TODO\n","  score = 0\n","  R = min(qr_count[key], len(ranking))\n","  for i in range(len(ranking)):\n","    rank = 1 if i <= qr_count[key] else 0\n","    if (rank):\n","      score += iprec(ranking, i+1, key)/R\n","  return score\n","######## >>>>> memuat qrels\n","\n","def load_qrels(qrel_file = \"/content/drive/MyDrive/IR/qrels.txt\", max_q_id = 30, max_doc_id = 1033):\n","  \"\"\" memuat query relevance judgment (qrels) \n","      dalam format dictionary of dictionary\n","      qrels[query id][document id]\n","\n","      dimana, misal, qrels[\"Q3\"][12] = 1 artinya Doc 12\n","      relevan dengan Q3; dan qrels[\"Q3\"][10] = 0 artinya\n","      Doc 10 tidak relevan dengan Q3.\n","\n","  \"\"\"\n","  qrels = {\"Q\" + str(i) : {i:0 for i in range(1, max_doc_id + 1)} \\\n","                 for i in range(1, max_q_id + 1)}\n","  with open(qrel_file) as file:\n","    for line in file:\n","      parts = line.strip().split()\n","      qid = parts[0]\n","      did = int(parts[1])\n","      qrels[qid][did] = 1\n","  return qrels\n","\n","\n","######## >>>>> EVALUASI !\n","\n","def eval_bm25(qrels, query_file = \"/content/drive/MyDrive/IR/queries.txt\", k = 1000, k1 = 1.2, b = 0.75):\n","  \"\"\" \n","    loop ke semua 30 query, hitung score di setiap query,\n","    lalu hitung MEAN SCORE over those 30 queries.\n","    untuk setiap query, kembalikan top-1000 documents\n","  \"\"\"\n","  BSBI_instance = BSBIIndex(data_dir = 'collection', \\\n","                          postings_encoding = VBEPostings, \\\n","                          output_dir = 'index')\n","\n","  with open(query_file) as file:\n","    rbp_scores = []\n","    dcg_scores = []\n","    ap_scores = []\n","    for qline in file:\n","      parts = qline.strip().split()\n","      qid = parts[0]\n","      query = \" \".join(parts[1:])\n","\n","      # HATI-HATI, doc id saat indexing bisa jadi berbeda dengan doc id\n","      # yang tertera di qrels\n","      ranking = []\n","      for (score, doc) in BSBI_instance.retrieve_bm25(query, k = k, k1=k1, b=b):\n","          did = int(re.search(r'.*\\/(\\d*)\\.txt', doc).group(1))\n","          ranking.append(qrels[qid][did])\n","      rbp_scores.append(rbp(ranking))\n","      dcg_scores.append(dcg(ranking))\n","      ap_scores.append(ap(ranking))\n","\n","  print(\"Hasil evaluasi BM25 terhadap 30 queries dengan k1 {k1} dan b {b}\".format(k1=k1, b=b))\n","  print(\"RBP score =\", sum(rbp_scores) / len(rbp_scores))\n","  print(\"DCG score =\", sum(dcg_scores) / len(dcg_scores))\n","  print(\"AP score  =\", sum(ap_scores) / len(ap_scores))\n","\n","def eval_bm25_ideal_qrels(qrels, query_file = \"/content/drive/MyDrive/IR/queries.txt\", k = 1000, k1 = 1.2, b = 0.75):\n","  \"\"\" \n","    loop ke semua 30 query, hitung score di setiap query,\n","    lalu hitung MEAN SCORE over those 30 queries.\n","    untuk setiap query, kembalikan top-1000 documents\n","  \"\"\"\n","  BSBI_instance = BSBIIndex(data_dir = 'collection', \\\n","                          postings_encoding = VBEPostings, \\\n","                          output_dir = 'index')\n","\n","  with open(query_file) as file:\n","    rbp_scores = []\n","    dcg_scores = []\n","    ap_scores = []\n","    for qline in file:\n","      parts = qline.strip().split()\n","      qid = parts[0]\n","      query = \" \".join(parts[1:])\n","\n","      # HATI-HATI, doc id saat indexing bisa jadi berbeda dengan doc id\n","      # yang tertera di qrels\n","      ranking = []\n","      for (score, doc) in BSBI_instance.retrieve_bm25(query, k = k, k1=k1, b=b):\n","          did = int(re.search(r'.*\\/(\\d*)\\.txt', doc).group(1))\n","          ranking.append(qrels[qid][did])\n","      rbp_scores.append(irbp(ranking, qid))\n","      dcg_scores.append(idcg(ranking, qid))\n","      ap_scores.append(iap(ranking, qid))\n","\n","  print(\"Hasil evaluasi BM25 Ideal jika semua qrels didapatkan pada 30 queries dengan k1 {k1} dan b {b}\".format(k1=k1, b=b))\n","  print(\"RBP score =\", sum(rbp_scores) / len(rbp_scores))\n","  print(\"DCG score =\", sum(dcg_scores) / len(dcg_scores))\n","  print(\"AP score  =\", sum(ap_scores) / len(ap_scores))\n","\n","def eval_bm25_ideal_serp(qrels, query_file = \"/content/drive/MyDrive/IR/queries.txt\", k = 1000, k1 = 1.2, b = 0.75):\n","  \"\"\" \n","    loop ke semua 30 query, hitung score di setiap query,\n","    lalu hitung MEAN SCORE over those 30 queries.\n","    untuk setiap query, kembalikan top-1000 documents\n","  \"\"\"\n","  BSBI_instance = BSBIIndex(data_dir = 'collection', \\\n","                          postings_encoding = VBEPostings, \\\n","                          output_dir = 'index')\n","\n","  with open(query_file) as file:\n","    rbp_scores = []\n","    dcg_scores = []\n","    ap_scores = []\n","    for qline in file:\n","      parts = qline.strip().split()\n","      qid = parts[0]\n","      query = \" \".join(parts[1:])\n","\n","      # HATI-HATI, doc id saat indexing bisa jadi berbeda dengan doc id\n","      # yang tertera di qrels\n","      ranking = []\n","      for (score, doc) in BSBI_instance.retrieve_bm25(query, k = k, k1=k1, b=b):\n","          did = int(re.search(r'.*\\/(\\d*)\\.txt', doc).group(1))\n","          ranking.append(qrels[qid][did])\n","          ranking = sorted(ranking, reverse=True)\n","      rbp_scores.append(rbp(ranking))\n","      dcg_scores.append(dcg(ranking))\n","      ap_scores.append(ap(ranking))\n","\n","  print(\"Hasil evaluasi BM25 Ideal ketika semua yang relevant ada di top {k} terhadap 30 queries dengan k1 {k1} dan b {b}\".format(k=k, k1=k1, b=b))\n","  print(\"RBP score =\", sum(rbp_scores) / len(rbp_scores))\n","  print(\"DCG score =\", sum(dcg_scores) / len(dcg_scores))\n","  print(\"AP score  =\", sum(ap_scores) / len(ap_scores))\n","\n","def eval_letor_mono(qrels, query_file = \"/content/drive/MyDrive/IR/queries.txt\", k = 1000, k1 = 1.2, b = 0.75, model_path=\"/content/drive/MyDrive/IR/mono roberta/checkpoint/final.h5\"):\n","  \"\"\" \n","    loop ke semua 30 query, hitung score di setiap query,\n","    lalu hitung MEAN SCORE over those 30 queries.\n","    untuk setiap query, kembalikan top-1000 documents\n","  \"\"\"\n","  BSBI_instance = BSBIIndex(data_dir = 'collection', \\\n","                          postings_encoding = VBEPostings, \\\n","                          output_dir = 'index')\n","  # letor_instance = LetorDPR(\"allenai/biomed_roberta_base\")\n","  letor_instance = LetorMono(\"allenai/biomed_roberta_base\")\n","  letor_instance.prepare_model(model_path)\n","  num_lines = sum(1 for line in open(query_file, 'r'))\n","  with open(query_file) as file:\n","    rbp_scores = []\n","    dcg_scores = []\n","    ap_scores = []\n","    for line in tqdm(file, total=num_lines):\n","      parts = line.strip().split()\n","      qid = parts[0]\n","      query = \" \".join(parts[1:])\n","\n","      # HATI-HATI, doc id saat indexing bisa jadi berbeda dengan doc id\n","      # yang tertera di qrels\n","      ranking = []\n","      bsbi = BSBI_instance.retrieve_bm25(query, k = k, k1=k1, b=b)\n","      letor = letor_instance.reranking(query, bsbi)\n","      for (score, doc) in letor:\n","          did = int(re.search(r'.*\\/(\\d*)\\.txt', doc).group(1))\n","          ranking.append(qrels[qid][did])\n","      rbp_scores.append(rbp(ranking))\n","      dcg_scores.append(dcg(ranking))\n","      ap_scores.append(ap(ranking))\n","  print(\"Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 {k1} dan b {b}\".format(k1=k1, b=b))\n","  print(\"RBP score =\", sum(rbp_scores) / len(rbp_scores))\n","  print(\"DCG score =\", sum(dcg_scores) / len(dcg_scores))\n","  print(\"AP score  =\", sum(ap_scores) / len(ap_scores))\n","\n","def eval_letor_mono(qrels, query_file = \"/content/drive/MyDrive/IR/queries.txt\", k = 1000, k1 = 1.2, b = 0.75, model_path=\"/content/drive/MyDrive/IR/mono roberta/checkpoint/final.h5\"):\n","  \"\"\" \n","    loop ke semua 30 query, hitung score di setiap query,\n","    lalu hitung MEAN SCORE over those 30 queries.\n","    untuk setiap query, kembalikan top-1000 documents\n","  \"\"\"\n","  BSBI_instance = BSBIIndex(data_dir = 'collection', \\\n","                          postings_encoding = VBEPostings, \\\n","                          output_dir = 'index')\n","  # letor_instance = LetorDPR(\"allenai/biomed_roberta_base\")\n","  letor_instance = LetorMono(\"allenai/biomed_roberta_base\")\n","  letor_instance.prepare_model(model_path)\n","  num_lines = sum(1 for line in open(query_file, 'r'))\n","  with open(query_file) as file:\n","    rbp_scores = []\n","    dcg_scores = []\n","    ap_scores = []\n","    for line in tqdm(file, total=num_lines):\n","      parts = line.strip().split()\n","      qid = parts[0]\n","      query = \" \".join(parts[1:])\n","\n","      # HATI-HATI, doc id saat indexing bisa jadi berbeda dengan doc id\n","      # yang tertera di qrels\n","      ranking = []\n","      bsbi = BSBI_instance.retrieve_bm25(query, k = k, k1=k1, b=b)\n","      letor = letor_instance.reranking(query, bsbi)\n","      for (score, doc) in letor:\n","          did = int(re.search(r'.*\\/(\\d*)\\.txt', doc).group(1))\n","          ranking.append(qrels[qid][did])\n","      rbp_scores.append(rbp(ranking))\n","      dcg_scores.append(dcg(ranking))\n","      ap_scores.append(ap(ranking))\n","  print(\"Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 {k1} dan b {b}\".format(k1=k1, b=b))\n","  print(\"RBP score =\", sum(rbp_scores) / len(rbp_scores))\n","  print(\"DCG score =\", sum(dcg_scores) / len(dcg_scores))\n","  print(\"AP score  =\", sum(ap_scores) / len(ap_scores))\n","\n","def eval_letor_dpr(qrels, query_file = \"/content/drive/MyDrive/IR/queries.txt\", k = 1000, k1 = 1.2, b = 0.75, model_path=\"/content/drive/MyDrive/IR/mono roberta/checkpoint/final.h5\"):\n","  \"\"\" \n","    loop ke semua 30 query, hitung score di setiap query,\n","    lalu hitung MEAN SCORE over those 30 queries.\n","    untuk setiap query, kembalikan top-1000 documents\n","  \"\"\"\n","  BSBI_instance = BSBIIndex(data_dir = 'collection', \\\n","                          postings_encoding = VBEPostings, \\\n","                          output_dir = 'index')\n","  letor_instance = LetorDPR(\"allenai/biomed_roberta_base\")\n","  # letor_instance = LetorMono(\"allenai/biomed_roberta_base\")\n","  letor_instance.prepare_model(model_path)\n","  num_lines = sum(1 for line in open(query_file, 'r'))\n","  with open(query_file) as file:\n","    rbp_scores = []\n","    dcg_scores = []\n","    ap_scores = []\n","    for line in tqdm(file, total=num_lines):\n","      parts = line.strip().split()\n","      qid = parts[0]\n","      query = \" \".join(parts[1:])\n","\n","      # HATI-HATI, doc id saat indexing bisa jadi berbeda dengan doc id\n","      # yang tertera di qrels\n","      ranking = []\n","      bsbi = BSBI_instance.retrieve_bm25(query, k = k, k1=k1, b=b)\n","      letor = letor_instance.reranking(query, bsbi)\n","      for (score, doc) in letor:\n","          did = int(re.search(r'.*\\/(\\d*)\\.txt', doc).group(1))\n","          ranking.append(qrels[qid][did])\n","      rbp_scores.append(rbp(ranking))\n","      dcg_scores.append(dcg(ranking))\n","      ap_scores.append(ap(ranking))\n","  print()\n","  print(\"Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 {k1} dan b {b}\".format(k1=k1, b=b))\n","  print(\"RBP score =\", sum(rbp_scores) / len(rbp_scores))\n","  print(\"DCG score =\", sum(dcg_scores) / len(dcg_scores))\n","  print(\"AP score  =\", sum(ap_scores) / len(ap_scores))"]},{"cell_type":"markdown","metadata":{"id":"JSoyjX5Oj7Sm"},"source":["# Main"]},{"cell_type":"markdown","source":["## Metode\n","Dalam percobaan ini, saya menggunakan 3 metode yang berbeda. Yaitu 2 varian Mono Roberta dan 1 DPR Roberta. Semua model Roberta yang digunakan menggunakan model pretrained [biomed_roberta_base](https://huggingface.co/allenai/biomed_roberta_base). Untuk dataset tetap menggunakan nfcorpus namun hanya 3 fitur yang dipakai. Yaitu nontopic-titles, vid-titles, dan vid-desc. Dikarenakan data terlalu besar dan keterbatasan waktu, maka untuk 1 epoch akan menggunakan 1000 data yang dipilih secara acak dari keseluruhan dataset. Berikut penjelasan mengenai model yang digunakan,\n","\n","- Mono Roberta A   \n","Model ini menggunakan 1 buah Roberta dimana output vektor [CLS] akan dimasukkan ke dalam layer dense berukuran 3 karena menggunakan qrels dengan range relevan 1-3. Nilai skor dari query dan dokumen menggunakan nilai vektor dari indeks ke-2 atau nilai dari kelas 3 (paling relevan)\n","Pada saat training, saya menggabungkan nontopic-titles, vid-titles, dan vid-desc menjadi 1 query panjang. Intuisi dari metode ini agar model dapat mempelajari keseluruhan query yang digunakan untuk suatu dokumen. Setelah itu query tersebut dan dokumen akan ditokenisasi dengan maksimal panjang tokenisasi 256.\n","Akurasi terbaik didapatkan pada epoch ke 20.\n","\n","- [Mono Roberta B](https://colab.research.google.com/drive/1QmbqsE5X2i1quAVI1QT929O8E4c23js5?usp=sharing)\n","Arsitektur dan cara skoring ini sama seperti Mono Roberta A. Namun terdapat perbedaan pada training dataset. Pada varian ini nontopic-titles, vid-titles, dan vid-desc tidak digabung menjadi 1 query panjang. Namun akan dipilih secara acak fitur yang digunakan saat dilakukan training. Intuisi dari metode ini karena query yang diberikan oleh user hanyalah sebuah string pertanyaan saja. Sehingga dengan 1 fitur diharapkan dapat mencerminkan sifat user dalam membuat query. Namun untuk metode ini menggunakan tokenisasi dengan maksimal panjang tokenisasi 320.\n","Akurasi terbaik didapatkan pada epoch ke 23.\n","\n","Link colab untuk training Mono Roberta A sudah tertimpa oleh Mono Roberta B. Namun untuk proses pembuatan model sebagian besar sama. Perbedaan hanya terdapat pada penggabungan query menjadi 1. \n","\n","- [DPR Roberta](https://colab.research.google.com/drive/1WwRzZG6HDe9Et-WssGa3tVw01A2Y0swF?usp=sharing)\n","Untuk metode terakhir menggunakan teknik DPR dimana membutuhkan 2 model Roberta. Yaitu masing-masing query dan dokumen memiliki model Roberta tersendiri. Lalu hasil skoring didapatkan dengan mengalikan dot product dari vektor output token [CLS] query dan dokumen. Permasalahan dari model ini menjadi regresi sehingga menggunakan mean squared error (MSE) sebagai nilai loss. \n","Dikarenakan query dan dokumen menggunakan model Roberta yang berbeda, maka memiliki panjang tokenisasi yang berbeda. Query memiliki panjang tokenisasi 64 dan dokumen memiliki panjang tokenisasi 256.\n","Akurasi terbaik didapatkan pada epoch ke 15.\n"],"metadata":{"id":"m5UhEapFJ512"}},{"cell_type":"markdown","source":["## K = 2"],"metadata":{"id":"UZ0iuETaCOPm"}},{"cell_type":"code","source":["qrels = load_qrels()"],"metadata":{"id":"9J465VLWs1bn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eval_bm25_ideal_serp(qrels, k=2)\n","eval_bm25_ideal_qrels(qrels, k=2)"],"metadata":{"id":"eEg1jZQsCD7b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670659805269,"user_tz":-420,"elapsed":1226,"user":{"displayName":"Hendrico Kristiawan","userId":"15526653224856737825"}},"outputId":"bac6a0b7-94e2-4e61-9d7c-94d983bc4ad3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hasil evaluasi BM25 Ideal ketika semua yang relevant ada di top 2 terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.23866666666666672\n","DCG score = 1.1031625352381107\n","AP score  = 0.7666666666666667\n","Hasil evaluasi BM25 Ideal jika semua qrels didapatkan pada 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.36\n","DCG score = 1.6309297535714575\n","AP score  = 1.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":75752,"status":"ok","timestamp":1670659881004,"user":{"displayName":"Hendrico Kristiawan","userId":"15526653224856737825"},"user_tz":-420},"id":"eFSLixVv8yBt","outputId":"6d57783b-5234-4e59-8ddc-642703edb976"},"outputs":[{"output_type":"stream","name":"stdout","text":["Untuk K = 2\n","Raw BM25\n","Hasil evaluasi BM25 terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.23600000000000007\n","DCG score = 1.0785578521428747\n","AP score  = 0.7333333333333333\n","Mono Roberta A\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:09<00:00,  3.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.23600000000000007\n","DCG score = 1.0785578521428747\n","AP score  = 0.7333333333333333\n","Mono Roberta B\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:10<00:00,  2.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.23466666666666672\n","DCG score = 1.0662555105952565\n","AP score  = 0.7166666666666667\n","DPR Roberta\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:20<00:00,  1.47it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.2333333333333334\n","DCG score = 1.0539531690476385\n","AP score  = 0.7\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["k = 2\n","print(f\"Untuk K = {k}\")\n","print(\"Raw BM25\")\n","eval_bm25(qrels, k=k)\n","print(\"Mono Roberta A\")\n","eval_letor_mono(qrels, k=k, model_path=\"/content/drive/MyDrive/IR/mono roberta/checkpoint/20.h5\")  \n","print(\"Mono Roberta B\")\n","eval_letor_mono(qrels, k=k, model_path=\"/content/drive/MyDrive/IR/mono roberta/checkpoint/v2_23_0.785.h5\")  \n","print(\"DPR Roberta\")\n","eval_letor_dpr(qrels, k=k, model_path=\"/content/drive/MyDrive/IR/DPR Roberta/checkpoint/v2_15_0.571.h5\")  "]},{"cell_type":"markdown","source":["## K = 3"],"metadata":{"id":"zkPQk1ekEutC"}},{"cell_type":"code","source":["eval_bm25_ideal_serp(qrels, k=3)\n","eval_bm25_ideal_qrels(qrels, k=3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u6xlBb6VGSmF","executionInfo":{"status":"ok","timestamp":1670659881005,"user_tz":-420,"elapsed":14,"user":{"displayName":"Hendrico Kristiawan","userId":"15526653224856737825"}},"outputId":"633e9de2-8a07-43cd-99d5-5c841110ba15"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hasil evaluasi BM25 Ideal ketika semua yang relevant ada di top 3 terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.3413333333333333\n","DCG score = 1.5416508275000205\n","AP score  = 0.9333333333333333\n","Hasil evaluasi BM25 Ideal jika semua qrels didapatkan pada 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.48799999999999966\n","DCG score = 2.1309297535714578\n","AP score  = 1.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":78418,"status":"ok","timestamp":1670659959417,"user":{"displayName":"Hendrico Kristiawan","userId":"15526653224856737825"},"user_tz":-420},"id":"-JU82xYw8zPc","outputId":"3e6e4595-3f68-467f-a7e8-8281ab7894c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Untuk K = 3\n","Raw BM25\n","Hasil evaluasi BM25 terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.32133333333333336\n","DCG score = 1.411891185476208\n","AP score  = 0.7777777777777778\n","Mono Roberta A\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:17<00:00,  1.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.3306666666666666\n","DCG score = 1.4706198357143052\n","AP score  = 0.8555555555555555\n","Mono Roberta B\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:14<00:00,  2.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.3296\n","DCG score = 1.4662555105952566\n","AP score  = 0.8583333333333332\n","DPR Roberta\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:28<00:00,  1.04it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.3258666666666667\n","DCG score = 1.4372865023809718\n","AP score  = 0.8194444444444444\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["k = 3\n","print(f\"Untuk K = {k}\")\n","print(\"Raw BM25\")\n","eval_bm25(qrels, k=k)\n","print(\"Mono Roberta A\")\n","eval_letor_mono(qrels, k=k, model_path=\"/content/drive/MyDrive/IR/mono roberta/checkpoint/20.h5\")  \n","print(\"Mono Roberta B\")\n","eval_letor_mono(qrels, k=k, model_path=\"/content/drive/MyDrive/IR/mono roberta/checkpoint/v2_23_0.785.h5\")  \n","print(\"DPR Roberta\")\n","eval_letor_dpr(qrels, k=k, model_path=\"/content/drive/MyDrive/IR/DPR Roberta/checkpoint/v2_15_0.571.h5\")  "]},{"cell_type":"markdown","source":["## K = 5"],"metadata":{"id":"MDDe7QImGf3g"}},{"cell_type":"code","source":["eval_bm25_ideal_serp(qrels, k=5)\n","eval_bm25_ideal_qrels(qrels, k=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LTPw5Bi-GhTR","executionInfo":{"status":"ok","timestamp":1670659960187,"user_tz":-420,"elapsed":786,"user":{"displayName":"Hendrico Kristiawan","userId":"15526653224856737825"}},"outputId":"169bcc50-d901-4b85-f090-00e71ff219f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hasil evaluasi BM25 Ideal ketika semua yang relevant ada di top 5 terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.4784319999999999\n","DCG score = 2.1054509089838547\n","AP score  = 0.9666666666666667\n","Hasil evaluasi BM25 Ideal jika semua qrels didapatkan pada 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.6723199999999995\n","DCG score = 2.9484591188793936\n","AP score  = 1.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":114265,"status":"ok","timestamp":1670660074445,"user":{"displayName":"Hendrico Kristiawan","userId":"15526653224856737825"},"user_tz":-420},"id":"L71yHeSc8zqb","outputId":"e1985ed6-6061-4f59-ce19-01437ff6dd8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Untuk K = 5\n","Raw BM25\n","Hasil evaluasi BM25 terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.4257813333333333\n","DCG score = 1.8751578258173707\n","AP score  = 0.7676388888888889\n","Mono Roberta A\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.4517866666666666\n","DCG score = 2.0117121794656967\n","AP score  = 0.8887962962962963\n","Mono Roberta B\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:27<00:00,  1.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.4494186666666666\n","DCG score = 1.985664754640669\n","AP score  = 0.8502314814814815\n","DPR Roberta\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:47<00:00,  1.57s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.44077866666666665\n","DCG score = 1.9389812082741313\n","AP score  = 0.8178240740740742\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["k = 5\n","print(f\"Untuk K = {k}\")\n","print(\"Raw BM25\")\n","eval_bm25(qrels, k=k)\n","print(\"Mono Roberta A\")\n","eval_letor_mono(qrels, k=k, model_path=\"/content/drive/MyDrive/IR/mono roberta/checkpoint/20.h5\")  \n","print(\"Mono Roberta B\")\n","eval_letor_mono(qrels, k=k, model_path=\"/content/drive/MyDrive/IR/mono roberta/checkpoint/v2_23_0.785.h5\")  \n","print(\"DPR Roberta\")\n","eval_letor_dpr(qrels, k=k, model_path=\"/content/drive/MyDrive/IR/DPR Roberta/checkpoint/v2_15_0.571.h5\")  "]},{"cell_type":"markdown","source":["## K = 10"],"metadata":{"id":"aS8nivIzGja6"}},{"cell_type":"code","source":["eval_bm25_ideal_serp(qrels, k=10)\n","eval_bm25_ideal_qrels(qrels, k=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NvMG1hAGGk_r","executionInfo":{"status":"ok","timestamp":1670660075161,"user_tz":-420,"elapsed":731,"user":{"displayName":"Hendrico Kristiawan","userId":"15526653224856737825"}},"outputId":"61d9661d-9160-4d72-e8bd-000c09742fb6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hasil evaluasi BM25 Ideal ketika semua yang relevant ada di top 10 terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.6454066858666666\n","DCG score = 2.9499056054458275\n","AP score  = 1.0\n","Hasil evaluasi BM25 Ideal jika semua qrels didapatkan pada 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.8917310327466664\n","DCG score = 4.533923843877749\n","AP score  = 1.0033333333333332\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":208993,"status":"ok","timestamp":1670660284149,"user":{"displayName":"Hendrico Kristiawan","userId":"15526653224856737825"},"user_tz":-420},"id":"d2Iy_2W7I9R7","outputId":"c854485d-b894-4cb4-f6a4-33e542abe407"},"outputs":[{"output_type":"stream","name":"stdout","text":["Untuk K = 10\n","Raw BM25\n","Hasil evaluasi BM25 terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.5286920772266667\n","DCG score = 2.5792831014735467\n","AP score  = 0.7439320252792475\n","Mono Roberta A\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:47<00:00,  1.57s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.5766538581333334\n","DCG score = 2.728070097955343\n","AP score  = 0.8274681699840428\n","Mono Roberta B\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:49<00:00,  1.64s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.5620415044266666\n","DCG score = 2.706259755024765\n","AP score  = 0.8073017027798773\n","DPR Roberta\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [01:35<00:00,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.5227503104\n","DCG score = 2.5676963110969977\n","AP score  = 0.7313684964726631\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["k = 10\n","print(f\"Untuk K = {k}\")\n","print(\"Raw BM25\")\n","eval_bm25(qrels, k=k)\n","print(\"Mono Roberta A\")\n","eval_letor_mono(qrels, k=k, model_path=\"/content/drive/MyDrive/IR/mono roberta/checkpoint/20.h5\")  \n","print(\"Mono Roberta B\")\n","eval_letor_mono(qrels, k=k, model_path=\"/content/drive/MyDrive/IR/mono roberta/checkpoint/v2_23_0.785.h5\")  \n","print(\"DPR Roberta\")\n","eval_letor_dpr(qrels, k=k, model_path=\"/content/drive/MyDrive/IR/DPR Roberta/checkpoint/v2_15_0.571.h5\")  "]},{"cell_type":"markdown","source":["## K = 30"],"metadata":{"id":"Psf6dSSlGmjc"}},{"cell_type":"code","source":["eval_bm25_ideal_serp(qrels, k=30)\n","eval_bm25_ideal_qrels(qrels, k=30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AqUWFukYGohk","executionInfo":{"status":"ok","timestamp":1670660284893,"user_tz":-420,"elapsed":749,"user":{"displayName":"Hendrico Kristiawan","userId":"15526653224856737825"}},"outputId":"6088ea94-f6fb-47c0-fa39-aa4b401b12af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hasil evaluasi BM25 Ideal ketika semua yang relevant ada di top 30 terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.8273087802401464\n","DCG score = 4.368781060462851\n","AP score  = 1.0\n","Hasil evaluasi BM25 Ideal jika semua qrels didapatkan pada 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.9797155110789503\n","DCG score = 7.379722945036105\n","AP score  = 1.0429841878797386\n"]}]},{"cell_type":"code","source":["k = 30\n","print(f\"Untuk K = {k}\")\n","print(\"Raw BM25\")\n","eval_bm25(qrels, k=k)\n","print(\"Mono Roberta A\")\n","eval_letor_mono(qrels, k=k, model_path=\"/content/drive/MyDrive/IR/mono roberta/checkpoint/20.h5\")  \n","print(\"Mono Roberta B\")\n","eval_letor_mono(qrels, k=k, model_path=\"/content/drive/MyDrive/IR/mono roberta/checkpoint/v2_23_0.785.h5\")  \n","print(\"DPR Roberta\")\n","eval_letor_dpr(qrels, k=k, model_path=\"/content/drive/MyDrive/IR/DPR Roberta/checkpoint/v2_15_0.571.h5\")  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qOy007aptCWf","executionInfo":{"status":"ok","timestamp":1670660872426,"user_tz":-420,"elapsed":587540,"user":{"displayName":"Hendrico Kristiawan","userId":"15526653224856737825"}},"outputId":"29fd67dc-33f0-40f1-f08a-3cc401ee3491"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Untuk K = 30\n","Raw BM25\n","Hasil evaluasi BM25 terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.5619454442314002\n","DCG score = 3.6618154281564204\n","AP score  = 0.6322334163778885\n","Mono Roberta A\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [02:22<00:00,  4.74s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.6484293110148571\n","DCG score = 3.9004836636710016\n","AP score  = 0.7479991040305471\n","Mono Roberta B\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [02:22<00:00,  4.76s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.5837128860562546\n","DCG score = 3.7259496108123495\n","AP score  = 0.6670046040019276\n","DPR Roberta\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [04:47<00:00,  9.57s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.3963464757471192\n","DCG score = 3.176610615311709\n","AP score  = 0.4843128212608849\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["## K = 100"],"metadata":{"id":"Lfm2OSEcEP01"}},{"cell_type":"code","source":["eval_bm25_ideal_serp(qrels)\n","eval_bm25_ideal_qrels(qrels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AwifxkKaEUYF","executionInfo":{"status":"ok","timestamp":1670660873150,"user_tz":-420,"elapsed":739,"user":{"displayName":"Hendrico Kristiawan","userId":"15526653224856737825"}},"outputId":"d4181546-cd7d-4970-f990-8a1ee3805fc0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hasil evaluasi BM25 Ideal ketika semua yang relevant ada di top 1000 terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.9700789167583873\n","DCG score = 7.152670197701833\n","AP score  = 0.9999999999999999\n","Hasil evaluasi BM25 Ideal jika semua qrels didapatkan pada 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.9798521851946951\n","DCG score = 7.586956031097538\n","AP score  = 1.0464052405113176\n"]}]},{"cell_type":"code","source":["k = 100\n","print(f\"Untuk K = {k}\")\n","print(\"Raw BM25\")\n","eval_bm25(qrels, k=k)\n","print(\"Mono Roberta A\")\n","eval_letor_mono(qrels, k=k, model_path=\"/content/drive/MyDrive/IR/mono roberta/checkpoint/20.h5\")  \n","print(\"Mono Roberta B\")\n","eval_letor_mono(qrels, k=k, model_path=\"/content/drive/MyDrive/IR/mono roberta/checkpoint/v2_23_0.785.h5\")  \n","print(\"DPR Roberta\")\n","eval_letor_dpr(qrels, k=k, model_path=\"/content/drive/MyDrive/IR/DPR Roberta/checkpoint/v2_15_0.571.h5\")  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxq_QpQ1ERtO","executionInfo":{"status":"ok","timestamp":1670662663436,"user_tz":-420,"elapsed":1790292,"user":{"displayName":"Hendrico Kristiawan","userId":"15526653224856737825"}},"outputId":"55ccb5a7-8089-4ca2-a052-772b3f67a570"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Untuk K = 100\n","Raw BM25\n","Hasil evaluasi BM25 terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.5621172735609207\n","DCG score = 4.681040335265117\n","AP score  = 0.5025600764415022\n","Mono Roberta A\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [07:30<00:00, 15.02s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.6700296381578121\n","DCG score = 5.142652782024445\n","AP score  = 0.6832292078228343\n","Mono Roberta B\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [07:26<00:00, 14.89s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.5755932596724512\n","DCG score = 4.806462918663125\n","AP score  = 0.5688943828235057\n","DPR Roberta\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [14:37<00:00, 29.26s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.21767954431055989\n","DCG score = 3.5776180705960416\n","AP score  = 0.28350286137729136\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["## K = 1000 (Default)"],"metadata":{"id":"nVCMtt6IGqi2"}},{"cell_type":"code","source":["eval_bm25_ideal_serp(qrels)\n","eval_bm25_ideal_qrels(qrels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Z6dEfosGqGU","executionInfo":{"status":"ok","timestamp":1670662664202,"user_tz":-420,"elapsed":789,"user":{"displayName":"Hendrico Kristiawan","userId":"15526653224856737825"}},"outputId":"384a7180-df14-48c7-8ce2-9c08a4165d82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hasil evaluasi BM25 Ideal ketika semua yang relevant ada di top 1000 terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.9700789167583873\n","DCG score = 7.152670197701833\n","AP score  = 0.9999999999999999\n","Hasil evaluasi BM25 Ideal jika semua qrels didapatkan pada 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.9798521851946951\n","DCG score = 7.586956031097538\n","AP score  = 1.0464052405113176\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8061425,"status":"ok","timestamp":1670671664276,"user":{"displayName":"Hendrico Kristiawan","userId":"15526653224856737825"},"user_tz":-420},"id":"qOem48MYUtem","outputId":"f9937981-dd77-4f91-8cec-bcc9959db210"},"outputs":[{"output_type":"stream","name":"stdout","text":["Untuk K = 1000\n","Raw BM25\n","Hasil evaluasi BM25 terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.562117273564048\n","DCG score = 5.368178925799611\n","AP score  = 0.42314371344987417\n","Mono Roberta A\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [33:12<00:00, 66.41s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.6668407389547821\n","DCG score = 5.981620666841301\n","AP score  = 0.6028828197790805\n","Mono Roberta B\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [33:24<00:00, 66.81s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.4983931526352883\n","DCG score = 5.2228195438225935\n","AP score  = 0.4353467138778974\n","DPR Roberta\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [1:07:28<00:00, 134.94s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Hasil evaluasi BM25 Letor terhadap 30 queries dengan k1 1.2 dan b 0.75\n","RBP score = 0.12115606875671989\n","DCG score = 3.3960874335042224\n","AP score  = 0.14008696228875447\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["k = 1000\n","print(f\"Untuk K = {k}\")\n","print(\"Raw BM25\")\n","eval_bm25(qrels, k=k)\n","print(\"Mono Roberta A\")\n","eval_letor_mono(qrels, k=k, model_path=\"/content/drive/MyDrive/IR/mono roberta/checkpoint/20.h5\")  \n","print(\"Mono Roberta B\")\n","eval_letor_mono(qrels, k=k, model_path=\"/content/drive/MyDrive/IR/mono roberta/checkpoint/v2_23_0.785.h5\")  \n","print(\"DPR Roberta\")\n","eval_letor_dpr(qrels, k=k, model_path=\"/content/drive/MyDrive/IR/DPR Roberta/checkpoint/v2_15_0.571.h5\")  "]},{"cell_type":"markdown","metadata":{"id":"RLid-ZlzYEF3"},"source":["# Kesimpulan"]},{"cell_type":"markdown","source":["Kesimpulan yang saya dapatkan bahwa metode Mono Roberta A lebih baik dibandingkan Mono Roberta B maupun DPR Roberta. Untuk k pada range 2 - 5, ketiga metode masih lebih baik dibandingkan BM25 tanpa reranking. Namun pada k bernilai 10, DPR Roberta mendapatkan hasil yang sedikit lebih buruk dari pada BM25 saja. Hal ini disebabkan karena epoch yang kurang lama karena untuk 1 epoch membutuhkan waktu yg cukup lama untuk melatihnya. Sedangkan untuk Mono ROberta varian A dan B masih memberikan hasil yang lebih baik hingga k = 100. Untuk k = 1000, hanya Mono Roberta A saja yang menghasilkan hasil yang lebih baik dibandingkan hanya BM25. Sehingga dapat disimpulkan bahwa ketika semua query digabung pada  proses training, model akan lebih bisa mempelajari maksud dari query sehingga menghasilkan akurasi yang lebih baik. Hasil Mono Roberta A juga lebih baik dibandingkan lgbm ranker pada TP 3. Sehingga membuktikan attention pada transformer dapat menangkap konteks pada kalimat lebih baik dibandingkan LSI."],"metadata":{"id":"Zcu-2I1yk2vq"}}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["nVCMtt6IGqi2"],"toc_visible":true,"mount_file_id":"1SyH5Qx-H9GEbiBA7vqH8KHyfj7iWadYA","authorship_tag":"ABX9TyOZxjsDP0RQS82z1gRxeHa9"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e0ebf753bb3a440880b489dd7c2e2644":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e39423d94c694875996c24f4ac485f01","IPY_MODEL_20989918523b4ec8b81e0103d2039011","IPY_MODEL_3e00fdfa4c12432986f815e583cf0c07"],"layout":"IPY_MODEL_ee3de834e8b341a69c3a0595d208782e"}},"e39423d94c694875996c24f4ac485f01":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_282e6f992eda44278fdbbec26982c724","placeholder":"​","style":"IPY_MODEL_886a6d19748e42cbbf6c067a3ef57749","value":"Downloading: 100%"}},"20989918523b4ec8b81e0103d2039011":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_502bc0e2337d4db5854abbcf59b816e3","max":898822,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8d85f54585244ec58ccdad64729ec49b","value":898822}},"3e00fdfa4c12432986f815e583cf0c07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3285fc0713254c528fbcc68363d15c18","placeholder":"​","style":"IPY_MODEL_74ba9596bbbf432fab7fc3e1635a99d1","value":" 899k/899k [00:01&lt;00:00, 934kB/s]"}},"ee3de834e8b341a69c3a0595d208782e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"282e6f992eda44278fdbbec26982c724":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"886a6d19748e42cbbf6c067a3ef57749":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"502bc0e2337d4db5854abbcf59b816e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d85f54585244ec58ccdad64729ec49b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3285fc0713254c528fbcc68363d15c18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74ba9596bbbf432fab7fc3e1635a99d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3014f36332344ff5bb869e7cc74ce37b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_201bcfb40cec45fca500dc27efda5d9e","IPY_MODEL_c3a8dd6555fd4554a1847847e2d8f983","IPY_MODEL_fd8b17423af245139d9c6d7dd2b7aa54"],"layout":"IPY_MODEL_356fc7cdce6341688b55f9454909bc10"}},"201bcfb40cec45fca500dc27efda5d9e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23b4194295724f5c9633f0e43887be4b","placeholder":"​","style":"IPY_MODEL_353f1aca1ca147e2a1ebb4fda536135c","value":"Downloading: 100%"}},"c3a8dd6555fd4554a1847847e2d8f983":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9479ab7b73cc488193591493963616cc","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_abc073a72da3499391cc77482e1981e3","value":456318}},"fd8b17423af245139d9c6d7dd2b7aa54":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abc4549bb4284bdb93d901980a91962d","placeholder":"​","style":"IPY_MODEL_b7e32fa2168146be81b9cdc67d9fefc4","value":" 456k/456k [00:01&lt;00:00, 533kB/s]"}},"356fc7cdce6341688b55f9454909bc10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23b4194295724f5c9633f0e43887be4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"353f1aca1ca147e2a1ebb4fda536135c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9479ab7b73cc488193591493963616cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abc073a72da3499391cc77482e1981e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"abc4549bb4284bdb93d901980a91962d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7e32fa2168146be81b9cdc67d9fefc4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1031e6d90ff640099144d31e1ec55969":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c1f9608c2313445888b3239788f547ef","IPY_MODEL_d58aa0bdfcf24388b7c384a34e1e938a","IPY_MODEL_4173371099ea4b6db36d71a7d476e10b"],"layout":"IPY_MODEL_9083a86d40cc419aa7ba669cf331daef"}},"c1f9608c2313445888b3239788f547ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_faea5e14b35f4e359c617f558b1b7adc","placeholder":"​","style":"IPY_MODEL_15ffdfa4db2e4217a355c3672c67a273","value":"Downloading: 100%"}},"d58aa0bdfcf24388b7c384a34e1e938a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_97c30e467cec4895a52075189df4a70e","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ad004a5a3b04e30bf1dbd31e84d4a19","value":2}},"4173371099ea4b6db36d71a7d476e10b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01314a24a3864a42842f7c7f78966d71","placeholder":"​","style":"IPY_MODEL_bab646e5400b4769a58db0e089711736","value":" 2.00/2.00 [00:00&lt;00:00, 21.5B/s]"}},"9083a86d40cc419aa7ba669cf331daef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"faea5e14b35f4e359c617f558b1b7adc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15ffdfa4db2e4217a355c3672c67a273":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97c30e467cec4895a52075189df4a70e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ad004a5a3b04e30bf1dbd31e84d4a19":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"01314a24a3864a42842f7c7f78966d71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bab646e5400b4769a58db0e089711736":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"035fc08c3466460884e67bab7f9054b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4bab9fcd29234053b5026d0bfe667024","IPY_MODEL_5b2822d6c3004255ad30defda0d4bc5b","IPY_MODEL_5cde4d11cb334f75992b7c4765612172"],"layout":"IPY_MODEL_1cc92491c8aa4f6698ba50f6a5963f51"}},"4bab9fcd29234053b5026d0bfe667024":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a5e2826ef804b50891c250c70c39073","placeholder":"​","style":"IPY_MODEL_f7a374023b664017aca5ab5bcdf57190","value":"Downloading: 100%"}},"5b2822d6c3004255ad30defda0d4bc5b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_02af1c080367484eac6e17242fa54c73","max":150,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4ae101f4ab7f494fb8ed1c9325663178","value":150}},"5cde4d11cb334f75992b7c4765612172":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_900e4c7c93fc462db3884a782bfaa811","placeholder":"​","style":"IPY_MODEL_0d08b677bd654fad9fcda146dddffb42","value":" 150/150 [00:00&lt;00:00, 1.36kB/s]"}},"1cc92491c8aa4f6698ba50f6a5963f51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a5e2826ef804b50891c250c70c39073":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7a374023b664017aca5ab5bcdf57190":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02af1c080367484eac6e17242fa54c73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ae101f4ab7f494fb8ed1c9325663178":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"900e4c7c93fc462db3884a782bfaa811":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d08b677bd654fad9fcda146dddffb42":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b5922ee25e694fcf8d307e31ed35d283":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f2d302859e234ed18871e9a6965eab2d","IPY_MODEL_f2c955d03c39417db0dec7319072d87c","IPY_MODEL_21a474385bd14d2cafa9a80c5526c64a"],"layout":"IPY_MODEL_061df2e20e284569b7ac8a38c1f1c227"}},"f2d302859e234ed18871e9a6965eab2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c0792bd89454b019656e5bb6cc28711","placeholder":"​","style":"IPY_MODEL_e3ab9f7ef53d409ea640b1516117fd15","value":"Downloading: 100%"}},"f2c955d03c39417db0dec7319072d87c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5878106a99ae48189fc4c13c8c814d4a","max":185,"min":0,"orientation":"horizontal","style":"IPY_MODEL_22f881e0d935478aaf1db3509a9c8729","value":185}},"21a474385bd14d2cafa9a80c5526c64a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af99f65edf1648889bc01947ae68632a","placeholder":"​","style":"IPY_MODEL_4988aaa93fdd409d91adc5f77cc0e1f0","value":" 185/185 [00:00&lt;00:00, 1.79kB/s]"}},"061df2e20e284569b7ac8a38c1f1c227":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c0792bd89454b019656e5bb6cc28711":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3ab9f7ef53d409ea640b1516117fd15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5878106a99ae48189fc4c13c8c814d4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22f881e0d935478aaf1db3509a9c8729":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"af99f65edf1648889bc01947ae68632a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4988aaa93fdd409d91adc5f77cc0e1f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0921b9adbd644a9caefb4d6972275ab5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e798d7e9fbed431e820a4aac62ff3d6b","IPY_MODEL_27d1facf27de4874bccbc134bc8bd2cf","IPY_MODEL_932e67a91bce48a2aaa82c2da182d915"],"layout":"IPY_MODEL_e6308c36df2e40b9b74945b6aa83b26e"}},"e798d7e9fbed431e820a4aac62ff3d6b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d6445b12c34489b913f39f03c3597b5","placeholder":"​","style":"IPY_MODEL_5d169d9bf94d493cb993aa8faee13980","value":"Downloading: 100%"}},"27d1facf27de4874bccbc134bc8bd2cf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_29bfbaaa20b14fbea93b3d6c1eb55fda","max":430,"min":0,"orientation":"horizontal","style":"IPY_MODEL_723d69450b714d5a9184ae44254a8949","value":430}},"932e67a91bce48a2aaa82c2da182d915":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2e75f81fbcd4aa4b35238f6b3e0db69","placeholder":"​","style":"IPY_MODEL_9cf9ec9f89f24f6387258475c388faf5","value":" 430/430 [00:00&lt;00:00, 5.18kB/s]"}},"e6308c36df2e40b9b74945b6aa83b26e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d6445b12c34489b913f39f03c3597b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d169d9bf94d493cb993aa8faee13980":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29bfbaaa20b14fbea93b3d6c1eb55fda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"723d69450b714d5a9184ae44254a8949":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a2e75f81fbcd4aa4b35238f6b3e0db69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cf9ec9f89f24f6387258475c388faf5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"398af7a51e5943a1ae4e094d774df571":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_facf4780e7304086b990a327e578c7d6","IPY_MODEL_59d2ecfbc82f47a89feee46f1acb3ddf","IPY_MODEL_b19194cbead04c81ae9d715468c780c9"],"layout":"IPY_MODEL_31bfe2ed22504e218335a1bd66993b4b"}},"facf4780e7304086b990a327e578c7d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74d0f547bc84443a9308dd402441dd4b","placeholder":"​","style":"IPY_MODEL_fe56c50899b848c082220c6d443bf2d3","value":"Downloading: 100%"}},"59d2ecfbc82f47a89feee46f1acb3ddf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f6dacee2bff4de4aab4600c76d2c330","max":655615582,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e1f2e0689f04959aab6faba4962d213","value":655615582}},"b19194cbead04c81ae9d715468c780c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef9ccf227473421f80710037c39ea9fc","placeholder":"​","style":"IPY_MODEL_464c223a3e0b4f99a4929eca21a94c64","value":" 656M/656M [00:15&lt;00:00, 78.5MB/s]"}},"31bfe2ed22504e218335a1bd66993b4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74d0f547bc84443a9308dd402441dd4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe56c50899b848c082220c6d443bf2d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f6dacee2bff4de4aab4600c76d2c330":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e1f2e0689f04959aab6faba4962d213":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ef9ccf227473421f80710037c39ea9fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"464c223a3e0b4f99a4929eca21a94c64":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}